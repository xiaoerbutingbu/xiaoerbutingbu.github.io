<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>小二小二不停步</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2022-10-09T09:24:05.111Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>小二小二不停步</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Netty-IO</title>
    <link href="http://example.com/2022/10/06/Netty-IO/"/>
    <id>http://example.com/2022/10/06/Netty-IO/</id>
    <published>2022-10-06T09:16:29.000Z</published>
    <updated>2022-10-09T09:24:05.111Z</updated>
    
    <content type="html"><![CDATA[<h1 id="传统BIO"><a href="#传统BIO" class="headerlink" title="传统BIO"></a>传统BIO</h1><p>网络编程的基本模型是Client&#x2F;Server模型，就是两个进程之间相互通信，服务端提供位置信息（绑定的IP地址和监听端口），客户端通过连接操作向服务端监听的地址发起连接请求，通过三次握手建立连接，若建立成功就通过网络套接字通信</p><p>同步阻塞I&#x2F;O服务端通信模型（一客户端一线程）：</p><p><img src="/2022/10/06/Netty-IO/BIO.png"></p><p>采用BIO通信模型的服务端，通常由一个Acceptor线程负责监听客户端的连接，它接收到客户端连接请求后给每个客户端创建一个新线程进行链路处理，处理完成后通过输出流返回应答给客户端，线程销毁。一请求一应答通信类型。</p><p>该模型最大的问题就是<strong>缺乏弹性伸缩力</strong>：当客户端并发量增加，服务端的线程个数和客户端并发访问量呈正比关系，线程数的膨胀会让系统性能下降，并发访问量的持续增大，系统也会线程堆栈溢出、创建新线程失败等问题，最终进程会宕机或僵死，不能提供服务。</p><p>综上：每当一个新的客户端请求接入时，服务端必须创建一个新的线程处理新接入的客户端链路，一个线程只能处理一个客户端连接。在实际中，却常常有成千上万个客户端的并发连接，该模型显然不能满足场景。</p><h1 id="伪异步I-x2F-O"><a href="#伪异步I-x2F-O" class="headerlink" title="伪异步I&#x2F;O"></a>伪异步I&#x2F;O</h1><p>同步阻塞I&#x2F;O的一个链路需要一个线程处理，所以可以通过一个线程池处理多个客户端的请求接入，形成客户端个数M，线程池最大线程数N，M可以远大于N。线程池可以灵活调配线程资源，设置线程的最大值，防止由于海量并发接入导致线程耗尽。</p><p>伪异步I&#x2F;O服务端通信模型：</p><p><img src="/2022/10/06/Netty-IO/WIO.png"></p><p>当有新客户端接入，将客户端的socket封装成一个Task投递到后斗你的线程池中处理，JDK的线程池维护一个消息嘟列和N个活跃线程，对消息队列中的任务进行处理。由于线程池可以设置消息队列的大小和最大线程数，所以它占用的资源可控，不会让资源耗尽或宕机。</p><p>伪异步I&#x2F;O实际上只是对之前的I&#x2F;O模型的一个简单优化，无法从根本上解决同步I&#x2F;O导致的通信线程阻塞问题；如果所有可用线程都被服务器阻塞，那么后续所有I&#x2F;O消息都会在消息队列中排队；因为线程池采用阻塞队列实现，当队列挤满，后续接入队列的操作也会被阻塞；因为前端只有一个Accptor线程接收客户端接入，它被阻塞在线程池的同步阻塞队列后，新客户端请求消息会被拒绝，客户端会发生大量的连接超时；</p><h1 id="NIO"><a href="#NIO" class="headerlink" title="NIO"></a>NIO</h1><p>NIO提供了SocketChannel和ServerSocketChannel两种套接字通道实现，阻塞和非阻塞两种。</p><p>相关概念：</p><ul><li>缓冲区Buffer：一个对象，包含一些要写入或者要读出的数据。在面向流的I&#x2F;O中，可以将数据直接写入或者直接读到Stream对象中。NIO库中，<em><strong>所有数据都是用缓冲区处理</strong></em>。Buffer实质上是一个数组（最常见的就是ByteBuffer，所以它还提供了特有的一些操作），当然还提供了对数据的结构化访问以及维护读写位置等信息</li><li>通道Channel：就好比自来水管，网络数据通过Channel读取和写入；<strong>通道与流不同就在于通道是双向的，流只在一个方向上移动，而通道可用于读、写或同时进行</strong>；&#x3D;&#x3D;全双工&#x3D;&#x3D;，所以比流更好映射操作系统的API；可以分为两大类：对网略读写的SelectableChannel和对文件操作的FileChannel</li><li>多路复用器Selector：是NIO的基础，它会不断轮询注册在其上Channel，若某个Channel发生读或写，这个Channel就处于就绪状态，会被Selector轮询出来，再通过SelectionKey获取就绪Channel集合，进行后续的I&#x2F;O操作；</li></ul><p>NIO服务端通信序列图</p><p><img src="/2022/10/06/Netty-IO/NIOS.png"></p><p>NIO客户端序列图:</p><p><img src="/2022/10/06/Netty-IO/NIOC.png"></p><p>NIO优点：</p><ul><li>客户端发起的连接是异步，可通过在多路复用器注册OP_CONNECT等后续结果，不像之前的客户端被同步阻塞</li><li>SocketChannel的读写都是异步，没有可读写的数据可以直接返回，这样I&#x2F;O通信线程就可以处理其他的链路</li><li>线程模型的优化：因为JDK的Selector在Linux等操作系统上通过epoll实现，它没有连接句柄数的限制，这样一个Selector线程可以同时处理大量客户端连接，性能也不会因客户端增加而线性下降，所以非常适合高性能、高负载的网络服务器</li></ul><h1 id="AIO"><a href="#AIO" class="headerlink" title="AIO"></a>AIO</h1><p>NIO2.0引入的新的异步通道，不需要通过多路复用器对注册的通道进行轮询操作即可实现异步读写，从而简化了NIO的编程模型。提供了异步文件通道和异步套接字的实现，异步通道提供两种方式获取操作结果：java.util.concurrent.Future类来表示异步操作的结果；在执行异步操作的时候穿衣个Java.nio.channels。</p><h1 id="对比I-x2F-O"><a href="#对比I-x2F-O" class="headerlink" title="对比I&#x2F;O"></a>对比I&#x2F;O</h1><p>异步非阻塞I&#x2F;O：只能被称为非阻塞I&#x2F;O，不能交异步非阻塞I&#x2F;O。JDK1.4的Selector基于select&#x2F;poll模型实现，是基于I&#x2F;O复用技术的非阻塞I&#x2F;O；JDK1.5优化了Selector，在底层使用epoll替换了select&#x2F;poll，上层的API不变，没有改变I&#x2F;O的模型；JDK1.7提供NIO2.0新增了异步的套接字通道，才会真的异步I&#x2F;O，在异步I&#x2F;O操作的时候可以传递信号变量，当操作完成后会回调相关方法，异步I&#x2F;O才是AIO</p><p>多路复用器：NIO的关键是I&#x2F;O多路复用技术，技术核心就是通过Selector轮询注册在其上的Channel，当发现某个或多个Channel处于就绪状态，返回就绪态的Channel选择键集合，进行I&#x2F;O操作。</p><p>伪异步I&#x2F;O：NIO没有流行前，为了Tomcat通信线程同步I&#x2F;O导致业务线程被挂住的问题。所以就在通信线程和业务线程之前做个缓冲区，缓冲区用于隔离I&#x2F;O线程和业务线程间的直接访问</p><h1 id="不用Java-NIO而用Netty"><a href="#不用Java-NIO而用Netty" class="headerlink" title="不用Java NIO而用Netty"></a>不用Java NIO而用Netty</h1><p>不用NIO的原因</p><ul><li>NIO的类库和API繁杂，使用麻烦，要熟练使用相关API。Selector、ServerSocketChannel、SocketChannel、ByteBuffer</li><li>需要具备其他的额外技能。比如java多线程编程</li><li>可靠性能力补齐，工作量和难度都打</li><li>JDK NIO的BUG。比如：epoll 会导致Selector空轮序，而让CPU消耗100%，只是概率降低</li></ul><p>选Netty：</p><ul><li>API使用简单，开发门槛低</li><li>功能强大，预设置了多种编码解码功能，支持多种主流协议</li><li>定制能力强，可通过ChannelHandler对通信框架灵活的拓展</li><li>性能高，对比其他NIO框架，Netty综合性能优</li><li>社区活跃，版本迭代周期短，有BUG可及时修复</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;传统BIO&quot;&gt;&lt;a href=&quot;#传统BIO&quot; class=&quot;headerlink&quot; title=&quot;传统BIO&quot;&gt;&lt;/a&gt;传统BIO&lt;/h1&gt;&lt;p&gt;网络编程的基本模型是Client&amp;#x2F;Server模型，就是两个进程之间相互通信，服务端提供位置信息（绑定的I</summary>
      
    
    
    
    <category term="网络编程" scheme="http://example.com/categories/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"/>
    
    
    <category term="Netty" scheme="http://example.com/tags/Netty/"/>
    
  </entry>
  
  <entry>
    <title>LinkedHashMap</title>
    <link href="http://example.com/2022/10/03/LinkedHashMap/"/>
    <id>http://example.com/2022/10/03/LinkedHashMap/</id>
    <published>2022-10-03T11:30:01.000Z</published>
    <updated>2022-10-04T11:34:53.581Z</updated>
    
    <content type="html"><![CDATA[<h1 id="简述"><a href="#简述" class="headerlink" title="简述"></a>简述</h1><p>实现是通过键值对维护一个双向链表，保证了<em><strong>元素迭代的顺序</strong></em>，该顺序可是插入顺序也可是访问顺序</p><p>可以认为是：HashMap+LinkedList</p><p>可以用作缓存</p><h1 id="源码"><a href="#源码" class="headerlink" title="源码"></a>源码</h1><h2 id="核心"><a href="#核心" class="headerlink" title="核心"></a>核心</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//内部类，存储K-V键值对   </span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">Entry</span>&lt;K,V&gt; <span class="keyword">extends</span> <span class="title class_">HashMap</span>.Node&lt;K,V&gt; &#123;</span><br><span class="line">    <span class="comment">//前驱指针和后驱指针</span></span><br><span class="line">        Entry&lt;K,V&gt; before, after;</span><br><span class="line">    <span class="comment">//next用于维护HashMap指定table位置上连接的Entry的顺序</span></span><br><span class="line">        Entry(<span class="type">int</span> hash, K key, V value, Node&lt;K,V&gt; next) &#123;</span><br><span class="line">            <span class="built_in">super</span>(hash, key, value, next);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">LinkedHashMap</span>&lt;K,V&gt; <span class="keyword">extends</span> <span class="title class_">HashMap</span>&lt;K,V&gt; <span class="keyword">implements</span> <span class="title class_">Map</span>&lt;K,V&gt;</span><br><span class="line">&#123;</span><br><span class="line"><span class="comment">//头尾指针</span></span><br><span class="line"><span class="keyword">transient</span> LinkedHashMap.Entry&lt;K,V&gt; head;</span><br><span class="line">    <span class="keyword">transient</span> LinkedHashMap.Entry&lt;K,V&gt; tail;</span><br><span class="line">    <span class="comment">//指定LinkedHashMap的排序方式，true就为访问顺序排序，false就为插入顺序排序</span></span><br><span class="line">    <span class="keyword">final</span> <span class="type">boolean</span> accessOrder;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="维护"><a href="#维护" class="headerlink" title="维护"></a>维护</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//在节点删除后，维护链表，传入删除的节点</span></span><br><span class="line"><span class="keyword">void</span> <span class="title function_">afterNodeRemoval</span><span class="params">(Node&lt;K,V&gt; e)</span> &#123; <span class="comment">// unlink</span></span><br><span class="line">    <span class="comment">//p指向待删除元素，b执行前驱，a执行后驱</span></span><br><span class="line">    LinkedHashMap.Entry&lt;K,V&gt; p =</span><br><span class="line">        (LinkedHashMap.Entry&lt;K,V&gt;)e, b = p.before, a = p.after;</span><br><span class="line">    <span class="comment">//这里执行双向链表删除p节点操作，很简单。</span></span><br><span class="line">    p.before = p.after = <span class="literal">null</span>;</span><br><span class="line">    <span class="keyword">if</span> (b == <span class="literal">null</span>)</span><br><span class="line">        head = a;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        b.after = a;</span><br><span class="line">    <span class="keyword">if</span> (a == <span class="literal">null</span>)</span><br><span class="line">        tail = b;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        a.before = b;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//在节点被访问后根据accessOrder判断是否需要调整链表顺序</span></span><br><span class="line">  <span class="keyword">void</span> <span class="title function_">afterNodeAccess</span><span class="params">(Node&lt;K,V&gt; e)</span> &#123; <span class="comment">// move node to last</span></span><br><span class="line">      LinkedHashMap.Entry&lt;K,V&gt; last;</span><br><span class="line">      <span class="comment">//如果accessOrder为false，什么都不做</span></span><br><span class="line">      <span class="keyword">if</span> (accessOrder &amp;&amp; (last = tail) != e) &#123;</span><br><span class="line">          <span class="comment">//p指向待删除元素，b执行前驱，a执行后驱</span></span><br><span class="line">          LinkedHashMap.Entry&lt;K,V&gt; p =</span><br><span class="line">              (LinkedHashMap.Entry&lt;K,V&gt;)e, b = p.before, a = p.after;</span><br><span class="line">          <span class="comment">//这里执行双向链表删除操作</span></span><br><span class="line">          p.after = <span class="literal">null</span>;</span><br><span class="line">          <span class="keyword">if</span> (b == <span class="literal">null</span>)</span><br><span class="line">              head = a;</span><br><span class="line">          <span class="keyword">else</span></span><br><span class="line">              b.after = a;</span><br><span class="line">          <span class="keyword">if</span> (a != <span class="literal">null</span>)</span><br><span class="line">              a.before = b;</span><br><span class="line">          <span class="keyword">else</span></span><br><span class="line">              last = b;</span><br><span class="line">          <span class="comment">//这里执行将p放到尾部</span></span><br><span class="line">          <span class="keyword">if</span> (last == <span class="literal">null</span>)</span><br><span class="line">              head = p;</span><br><span class="line">          <span class="keyword">else</span> &#123;</span><br><span class="line">              p.before = last;</span><br><span class="line">              last.after = p;</span><br><span class="line">          &#125;</span><br><span class="line">          tail = p;</span><br><span class="line">          <span class="comment">//保证并发读安全。</span></span><br><span class="line">          ++modCount;</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="get"><a href="#get" class="headerlink" title="get"></a>get</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 调用hashmap的getNode方法获取到值之后，维护链表</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> V <span class="title function_">get</span><span class="params">(Object key)</span> &#123;</span><br><span class="line">    Node&lt;K,V&gt; e;</span><br><span class="line">    <span class="keyword">if</span> ((e = getNode(hash(key), key)) == <span class="literal">null</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">    <span class="keyword">if</span> (accessOrder)</span><br><span class="line">        afterNodeAccess(e);</span><br><span class="line">    <span class="keyword">return</span> e.value;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="put"><a href="#put" class="headerlink" title="put"></a>put</h2><p>就是HashMap的put方法</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">    <span class="comment">//默认的传入的evict是true</span></span><br><span class="line">    <span class="keyword">final</span> V <span class="title function_">putVal</span><span class="params">(<span class="type">int</span> hash, K key, V value, <span class="type">boolean</span> onlyIfAbsent,</span></span><br><span class="line"><span class="params">                   <span class="type">boolean</span> evict)</span> &#123;</span><br><span class="line">        ......</span><br><span class="line">            <span class="keyword">if</span> (e != <span class="literal">null</span>) &#123; <span class="comment">// existing mapping for key</span></span><br><span class="line">                <span class="comment">//如果e不为null，此时的e指向的就是在map中的那个插入点，所以这个时候来赋值。</span></span><br><span class="line">                <span class="type">V</span> <span class="variable">oldValue</span> <span class="operator">=</span> e.value;</span><br><span class="line">                <span class="comment">// onlyIfAbsent入口参数，为true，则不更新value。</span></span><br><span class="line">                <span class="comment">//这个地方的主要作用主要控制如果map中已经有那个key了，是否需要需要更新值</span></span><br><span class="line">                <span class="keyword">if</span> (!onlyIfAbsent || oldValue == <span class="literal">null</span>)</span><br><span class="line">                    e.value = value;</span><br><span class="line">                <span class="comment">//这里其实是插入成功后执行的，获得的效果就是将e放到了链表结尾。</span></span><br><span class="line">                <span class="comment">//所以afterNodeInsertion方法就算什么都不做也可以。</span></span><br><span class="line">                <span class="comment">//但是如果accessOrder为false，那么我们新插入的节点，都不会进入链表了</span></span><br><span class="line">                afterNodeAccess(e);</span><br><span class="line">                <span class="keyword">return</span> oldValue;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//fast-fail机制的实现，为了保证并发读安全。</span></span><br><span class="line">        ++modCount;</span><br><span class="line">        <span class="comment">//容器中的键值对数自增，如果大于了阈值，开始扩容</span></span><br><span class="line">        <span class="keyword">if</span> (++size &gt; threshold)</span><br><span class="line">            resize();</span><br><span class="line">        afterNodeInsertion(evict);</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">//其中会在合适的地方对链表进行相应的维护</span></span><br></pre></td></tr></table></figure><h1 id="对比HashMap"><a href="#对比HashMap" class="headerlink" title="对比HashMap"></a>对比HashMap</h1><p>LinkedHshMap虽然继承了HashMap，但实现了双线链表，有固定的顺序，与插入entry的顺序一样，有序性的表现就是遍历输出的顺序与put进去的顺序一致；HashMap存储是无序的；因为LinkedHashMap是HashMap的子类，总之具备HashMap的所有特性，就多了一个双向链表维护内部数据的顺序关系</p><p>两者都是非线程安全、都实现了序列化接口等、都支持null键和值、都不同步</p><h1 id="实现LRU算法"><a href="#实现LRU算法" class="headerlink" title="实现LRU算法"></a>实现LRU算法</h1><p><img src="/2022/10/03/LinkedHashMap/LRU.png"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;简述&quot;&gt;&lt;a href=&quot;#简述&quot; class=&quot;headerlink&quot; title=&quot;简述&quot;&gt;&lt;/a&gt;简述&lt;/h1&gt;&lt;p&gt;实现是通过键值对维护一个双向链表，保证了&lt;em&gt;&lt;strong&gt;元素迭代的顺序&lt;/strong&gt;&lt;/em&gt;，该顺序可是插入顺序也可是访问顺序</summary>
      
    
    
    
    <category term="基础" scheme="http://example.com/categories/%E5%9F%BA%E7%A1%80/"/>
    
    
    <category term="Map" scheme="http://example.com/tags/Map/"/>
    
  </entry>
  
  <entry>
    <title>TreeMap</title>
    <link href="http://example.com/2022/09/30/TreeMap/"/>
    <id>http://example.com/2022/09/30/TreeMap/</id>
    <published>2022-09-30T11:38:30.000Z</published>
    <updated>2022-10-04T15:20:14.005Z</updated>
    
    <content type="html"><![CDATA[<h1 id="简述"><a href="#简述" class="headerlink" title="简述"></a>简述</h1><p>存储K-V键值对，通过<em><strong>红黑树</strong></em>实现。因为红黑树本身是一颗自平衡的排序二叉树，节点的值大于左节点而小于右节点的值。所以在一定程度上，遍历时比较高效的。</p><p>它是<em><strong>有序</strong></em>的集合（因为它实现了NavigableMap接口，该接口拓展了SortedMap接口，又拓展Map接口）。而且由红黑树实现的，每个key-value都作为一个红黑树的节点。如果在调用TreeMap的构造函数时没有指定比较器，则根据key执行自然排序。</p><p>遍历分两步：通过entrySet()或keySet()或value获取相应的集合；再迭代器遍历该集合</p><p><img src="/2022/09/30/TreeMap/jiegou.png"></p><h1 id="源码"><a href="#源码" class="headerlink" title="源码"></a>源码</h1><h2 id="核心参数"><a href="#核心参数" class="headerlink" title="核心参数"></a>核心参数</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TreeMap</span>&lt;K,V&gt;</span><br><span class="line">    <span class="keyword">extends</span> <span class="title class_">AbstractMap</span>&lt;K,V&gt;</span><br><span class="line">    <span class="keyword">implements</span> <span class="title class_">NavigableMap</span>&lt;K,V&gt;, Cloneable, java.io.Serializable</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Comparator&lt;? <span class="built_in">super</span> K&gt; comparator;</span><br><span class="line"><span class="comment">//内部结构，类似于HashMap的形式</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">transient</span> Entry&lt;K,V&gt; root;</span><br><span class="line"><span class="comment">//实际存储在实例的节点个数</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">transient</span> <span class="type">int</span> <span class="variable">size</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line"><span class="comment">//对树结构的修改次数</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">transient</span> <span class="type">int</span> <span class="variable">modCount</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="节点"><a href="#节点" class="headerlink" title="节点"></a>节点</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 键值对</span></span><br><span class="line">  <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">class</span> <span class="title class_">Entry</span>&lt;K,V&gt; <span class="keyword">implements</span> <span class="title class_">Map</span>.Entry&lt;K,V&gt; &#123;</span><br><span class="line">      K key; <span class="comment">// key 值</span></span><br><span class="line">      V value; <span class="comment">// value 值</span></span><br><span class="line">      java.util.TreeMap.Entry&lt;K,V&gt; left;  <span class="comment">// 指向左边的子节点</span></span><br><span class="line">      java.util.TreeMap.Entry&lt;K,V&gt; right; <span class="comment">// 指向右边的子节点</span></span><br><span class="line">      java.util.TreeMap.Entry&lt;K,V&gt; parent; <span class="comment">// 指向父节点</span></span><br><span class="line">      <span class="type">boolean</span> <span class="variable">color</span> <span class="operator">=</span> BLACK; <span class="comment">// 默认节点颜色 黑</span></span><br><span class="line"></span><br><span class="line">      <span class="comment">// 初始化 Entry</span></span><br><span class="line">      Entry(K key, V value, java.util.TreeMap.Entry&lt;K,V&gt; parent) &#123;</span><br><span class="line">          <span class="built_in">this</span>.key = key;</span><br><span class="line">          <span class="built_in">this</span>.value = value;</span><br><span class="line">          <span class="built_in">this</span>.parent = parent;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">public</span> K <span class="title function_">getKey</span><span class="params">()</span> &#123;</span><br><span class="line">          <span class="keyword">return</span> key;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">public</span> V <span class="title function_">getValue</span><span class="params">()</span> &#123;</span><br><span class="line">          <span class="keyword">return</span> value;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">public</span> V <span class="title function_">setValue</span><span class="params">(V value)</span> &#123;</span><br><span class="line">          <span class="type">V</span> <span class="variable">oldValue</span> <span class="operator">=</span> <span class="built_in">this</span>.value;</span><br><span class="line">          <span class="built_in">this</span>.value = value;</span><br><span class="line">          <span class="keyword">return</span> oldValue;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="put"><a href="#put" class="headerlink" title="put"></a>put</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 添加一个数据</span></span><br><span class="line">    <span class="keyword">public</span> V <span class="title function_">put</span><span class="params">(K key, V value)</span> &#123;</span><br><span class="line">        <span class="comment">// 获取到红黑树的根节点</span></span><br><span class="line">        java.util.TreeMap.Entry&lt;K,V&gt; t = root;</span><br><span class="line">        <span class="comment">// 根节点为null, TreeMap中没有任何数据</span></span><br><span class="line">        <span class="keyword">if</span> (t == <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="comment">// 类型检查（可能为空）</span></span><br><span class="line">            compare(key, key);</span><br><span class="line">            <span class="comment">// 将当前的 key,value 生成根节点Entry</span></span><br><span class="line">            root = <span class="keyword">new</span> <span class="title class_">java</span>.util.TreeMap.Entry&lt;&gt;(key, value, <span class="literal">null</span>);</span><br><span class="line">            size = <span class="number">1</span>;</span><br><span class="line">            <span class="comment">// 操作次数 +1</span></span><br><span class="line">            modCount++;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="type">int</span> cmp;</span><br><span class="line">        <span class="comment">// 定义父节点</span></span><br><span class="line">        java.util.TreeMap.Entry&lt;K,V&gt; parent;</span><br><span class="line">        <span class="comment">// 比较器</span></span><br><span class="line">        Comparator&lt;? <span class="built_in">super</span> K&gt; cpr = comparator;</span><br><span class="line">        <span class="comment">// 用户传入的比较器不为空</span></span><br><span class="line">        <span class="keyword">if</span> (cpr != <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="comment">// 循环查找 key在二叉树对应的位置【即找到一个父节点】</span></span><br><span class="line">            <span class="keyword">do</span> &#123;</span><br><span class="line">                parent = t;</span><br><span class="line">                <span class="comment">// key与当前节点的key进行对比</span></span><br><span class="line">                cmp = cpr.compare(key, t.key);</span><br><span class="line">                <span class="comment">// cmp &lt; 0 找到当前节点的左子节点再去对比</span></span><br><span class="line">                <span class="keyword">if</span> (cmp &lt; <span class="number">0</span>)</span><br><span class="line">                    t = t.left;</span><br><span class="line">                <span class="comment">// cmp &gt; 0 找到当前节点的右子节点再去对比</span></span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span> (cmp &gt; <span class="number">0</span>)</span><br><span class="line">                    t = t.right;</span><br><span class="line">                <span class="comment">// cmp = 0 当前节点即是key的节点，用Value值替换掉旧值</span></span><br><span class="line">                <span class="keyword">else</span></span><br><span class="line">                    <span class="keyword">return</span> t.setValue(value);</span><br><span class="line">            &#125; <span class="keyword">while</span> (t != <span class="literal">null</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 使用 key 数据类型中默认的比较器，后面逻辑相同</span></span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (key == <span class="literal">null</span>)</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">NullPointerException</span>();</span><br><span class="line">            <span class="meta">@SuppressWarnings(&quot;unchecked&quot;)</span></span><br><span class="line">            Comparable&lt;? <span class="built_in">super</span> K&gt; k = (Comparable&lt;? <span class="built_in">super</span> K&gt;) key;</span><br><span class="line">            <span class="keyword">do</span> &#123;</span><br><span class="line">                parent = t;</span><br><span class="line">                cmp = k.compareTo(t.key);</span><br><span class="line">                <span class="keyword">if</span> (cmp &lt; <span class="number">0</span>)</span><br><span class="line">                    t = t.left;</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span> (cmp &gt; <span class="number">0</span>)</span><br><span class="line">                    t = t.right;</span><br><span class="line">                <span class="keyword">else</span></span><br><span class="line">                    <span class="keyword">return</span> t.setValue(value);</span><br><span class="line">            &#125; <span class="keyword">while</span> (t != <span class="literal">null</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 上面的代码如果直接return了表示。TreeMap中原来存在 key=参数key的节点，直接覆盖返回</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 下面的代码表示红黑树中不存在Key，需要为其创建节点， parent上面循环得到的二叉树的叶子及诶到哪</span></span><br><span class="line">        java.util.TreeMap.Entry&lt;K,V&gt; e = <span class="keyword">new</span> <span class="title class_">java</span>.util.TreeMap.Entry&lt;&gt;(key, value, parent);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// cmp &lt; 0 表示当前key生成的Entry是parent的左节点</span></span><br><span class="line">        <span class="keyword">if</span> (cmp &lt; <span class="number">0</span>)</span><br><span class="line">            parent.left = e;</span><br><span class="line">        <span class="comment">// cmp &gt; 0 表示当前key生成的Entry是parent的右节点</span></span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            parent.right = e;</span><br><span class="line">        <span class="comment">// 插入新的节点后，红黑树进行修复【节点颜色变化,左右旋等】，保证其扔就满足红黑树的特性</span></span><br><span class="line">        fixAfterInsertion(e);</span><br><span class="line">        size++;</span><br><span class="line">        modCount++;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="get"><a href="#get" class="headerlink" title="get"></a>get</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 通过 key 获取到Value的值</span></span><br><span class="line">   <span class="keyword">public</span> V <span class="title function_">get</span><span class="params">(Object key)</span> &#123;</span><br><span class="line">       java.util.TreeMap.Entry&lt;K,V&gt; p = getEntry(key);</span><br><span class="line">       <span class="keyword">return</span> (p==<span class="literal">null</span> ? <span class="literal">null</span> : p.value);</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 跟 key 值找到对应的 Entry</span></span><br><span class="line">   <span class="keyword">final</span> java.util.TreeMap.Entry&lt;K,V&gt; <span class="title function_">getEntry</span><span class="params">(Object key)</span> &#123;</span><br><span class="line">       <span class="keyword">if</span> (comparator != <span class="literal">null</span>)</span><br><span class="line">           <span class="keyword">return</span> getEntryUsingComparator(key);</span><br><span class="line">       <span class="comment">// TreeMap 中key 不可以为空</span></span><br><span class="line">       <span class="keyword">if</span> (key == <span class="literal">null</span>)</span><br><span class="line">           <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">NullPointerException</span>();</span><br><span class="line">       <span class="meta">@SuppressWarnings(&quot;unchecked&quot;)</span></span><br><span class="line">       Comparable&lt;? <span class="built_in">super</span> K&gt; k = (Comparable&lt;? <span class="built_in">super</span> K&gt;) key;</span><br><span class="line">       <span class="comment">// 得到TreeMap 中红黑树的 根节点</span></span><br><span class="line">       java.util.TreeMap.Entry&lt;K,V&gt; p = root;</span><br><span class="line">       <span class="comment">// 循环遍历</span></span><br><span class="line">       <span class="keyword">while</span> (p != <span class="literal">null</span>) &#123;</span><br><span class="line">           <span class="comment">// key和当前节点的key比较</span></span><br><span class="line">           <span class="type">int</span> <span class="variable">cmp</span> <span class="operator">=</span> k.compareTo(p.key);</span><br><span class="line">           <span class="comment">// 根据二叉树的原理，</span></span><br><span class="line">           <span class="comment">// cmp &lt; 0 找左节点</span></span><br><span class="line">           <span class="keyword">if</span> (cmp &lt; <span class="number">0</span>)</span><br><span class="line">               p = p.left;</span><br><span class="line">           <span class="comment">// cmp &gt; 0 找右节点</span></span><br><span class="line">           <span class="keyword">else</span> <span class="keyword">if</span> (cmp &gt; <span class="number">0</span>)</span><br><span class="line">               p = p.right;</span><br><span class="line">           <span class="comment">// 当前节点就是要查找的节点</span></span><br><span class="line">           <span class="keyword">else</span></span><br><span class="line">               <span class="keyword">return</span> p;</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="对比HashMap"><a href="#对比HashMap" class="headerlink" title="对比HashMap"></a>对比HashMap</h1><table><thead><tr><th align="center">TreeMap</th><th align="center">HashMap</th></tr></thead><tbody><tr><td align="center">有序，实现了SortedMap接口</td><td align="center">无序的，因为直接实现了Map接口</td></tr><tr><td align="center">底层是红黑树实现，时间效率较低，需要对比遍历</td><td align="center">由哈希桶实现，哈希算法本身的优势所以时间效率较高</td></tr><tr><td align="center">只保存需要保持的节点，占用内存较小</td><td align="center">要保存一个node的数组，数组下又有链表或红黑树，于是内存占用较大</td></tr><tr><td align="center">不允许null key</td><td align="center">允许null key</td></tr></tbody></table>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;简述&quot;&gt;&lt;a href=&quot;#简述&quot; class=&quot;headerlink&quot; title=&quot;简述&quot;&gt;&lt;/a&gt;简述&lt;/h1&gt;&lt;p&gt;存储K-V键值对，通过&lt;em&gt;&lt;strong&gt;红黑树&lt;/strong&gt;&lt;/em&gt;实现。因为红黑树本身是一颗自平衡的排序二叉树，节点的值大于左</summary>
      
    
    
    
    <category term="基础" scheme="http://example.com/categories/%E5%9F%BA%E7%A1%80/"/>
    
    
    <category term="Map" scheme="http://example.com/tags/Map/"/>
    
  </entry>
  
  <entry>
    <title>ElasticSearch简介</title>
    <link href="http://example.com/2022/09/27/ElasticSearch%E7%AE%80%E4%BB%8B/"/>
    <id>http://example.com/2022/09/27/ElasticSearch%E7%AE%80%E4%BB%8B/</id>
    <published>2022-09-27T08:45:21.000Z</published>
    <updated>2022-09-27T08:47:20.807Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Apache-Lucene"><a href="#Apache-Lucene" class="headerlink" title="Apache Lucene"></a>Apache Lucene</h1><h2 id="总体结构"><a href="#总体结构" class="headerlink" title="总体结构"></a>总体结构</h2><ul><li>文档：索引与搜索的主要数据载体，它包含一个或多个字段。存放将要写入索引或将从索引搜索出来的数据</li><li>字段：文档的一个片段，包括两个部分：字段的名称和内容</li><li>词项：搜索时的一个单位，代表文本中的某个词</li><li>词条：词项在字段中的一次出现，包括词项的文本、开始和结束的位移以及类型</li></ul><p>Lucene将写入索引的所有信息自支撑一种名为倒排索引的结构。该结构是一种将词项映射到文档的数据结构，工作方式与传统的关系型数据库不同，倒排索引是面向词项而不是文档。</p><p>索引存储了很多信息，比如词向量、各字段的原始信息、文档删除标记等。不用管存了什么，只需要了解索引中数据是如何组织的即可。</p><p>每个索引由多个段组成，每个段只会被创建一次但会被查询多次。索引期间，段在创建后就不会被修改。多个段会在<code>段合并</code>的的阶段合并在一起，而且是要么强制执行要么由Lucene的内在机制决定的某个时刻执行，合并后的段数量更少、更大。<em><strong>段合并很消耗I&#x2F;O</strong></em>，合并期间有些不会被使用的信息也会被清理</p><h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><p>分析：文档中的数据是如何转化为倒排索引的，查询串又是怎么转换为可用于搜索的词项</p><p>文本分析由分析器执行，分析器由分词器、过滤器、字符映射器组成。</p><ul><li>分词器：分词器将文本切割成词条，其中有各种额外信息的词项，信息包括：词项在原始文本中的位置、词项的长度。分词器的工作成果称为词条流，因为这些词条会被一个一个推送给过滤器。</li><li>过滤器：Lucene提供了很多现成的，也可以自定义实现心得。比如：小写过滤器（所有词条转化为小写）、ASCII过滤器（移除词条中所有非ASCII字符）。会逐个经过过滤器处理</li><li>字符映射器：用于调用分词之前的文本预处理操作。</li></ul><p>在索引期，Lucene会使用我们选择的分析器来处理文档的内容，可以对不同的字段使用不同的分析器。</p><h1 id="ElasticSearch"><a href="#ElasticSearch" class="headerlink" title="ElasticSearch"></a>ElasticSearch</h1><p>是一个可用于构建搜索应用的成品软件。</p><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><ul><li>索引：将数据存储在一个或多个索引中。索引就好比数据库，可以向索引写入文档或者从索引读取文档，并通过在ES内部使用Lucene将数据写入索引或从索引中检索数据。ES中的索引可能由一个或多个Lucene索引构成，具体细节由ES的索引分片、复制机制及其配置决定</li><li>文档：是ES的主要实体，由字段组成，每个字段都有它的字段名以及一个或多个字段值（有多个同名字段）。文档之间可能有各自不同的字段集合，且文档没有固定的模式或强制的结构。</li><li>类型：每个文档都有阈值对应的类型定义。允许用户在一个索引中存储多种文档类型，并未不同的文档类型提供不同的映射</li><li>节点：单个ES服务实例称为节点。大多时候一个ES节点足矣应付大多数简单的应用，但考虑到荣凑性或在数据膨胀到单击无法应付，会倾向使用多节点的ES集群</li><li>集群：数据量或查询压力超过单击负载时，需要多个节点来协同处理，所有节点组成的系统就是集群。集群同时是无间断提供服务的一种解决方案</li><li>分片：集群允许系统存储的数据总量超过单击容量。为了满足该需求，ES将数据散步到多个物理Lucene索引上，这些Lucene索引就是分片，散步分片的过程就是分片处理。ES会自动完成分片处理，并让该分片呈现出一个大索引。</li><li>副本：分片处理允许用户向ES集群推送超过单击容量的数据。副本就解决了访问压力过大时单击无法处理所有请求的问题。思路就是 为每个分片创建冗余的副本，处理查询时可以把这些副本用作最初的主分片。即使某个分片所在的节点宕机，ES可以使用其副本，数据就不会丢失，且可以在任意时间添加或移除副本。</li><li>网关：ES工作中，关于集群的状态，索引设置的各种信息都会被收集器来，并在网关中被持久化。</li></ul><h2 id="工作流程"><a href="#工作流程" class="headerlink" title="工作流程"></a>工作流程</h2><p>启动过程：当ES节点启动时，它使用广播（可配置为单播）来发现同一个集群中的其他节点并与他们连接。集群中会有一个节点选为管理节点（负载集群的状态管理以及在集群拓扑变化时做出变化，分发索引分片至集群的相应节点上），管理节点读取集群的状态信息，并在必要时恢复处理。该阶段，管理节点会检查所有索引分片并决定哪些分片将用于主分片，然后整个集群进入黄色状态；</p><p>故障检测：集群正常工作时，管理节点会检测所有可用节点，检测是否正在工作。若任何节点再预定义的超时时间内没有响应，则认为该节点断开，然后开始启动错误处理过程。这要在集群-分片之间重新做平衡，因为之前已断开节点上的那些分片不可用，剩下的节点要负相应的责任。</p><p>与ES通信：ES假设数据由URL携带或者以JSON，文档的形式由HTTP消息携带。ES在内部使用Java API进行节点间通信</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Apache-Lucene&quot;&gt;&lt;a href=&quot;#Apache-Lucene&quot; class=&quot;headerlink&quot; title=&quot;Apache Lucene&quot;&gt;&lt;/a&gt;Apache Lucene&lt;/h1&gt;&lt;h2 id=&quot;总体结构&quot;&gt;&lt;a href=&quot;#总体结构&quot;</summary>
      
    
    
    
    <category term="搜索引擎" scheme="http://example.com/categories/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/"/>
    
    
    <category term="ElasticSearch" scheme="http://example.com/tags/ElasticSearch/"/>
    
  </entry>
  
  <entry>
    <title>JDK19</title>
    <link href="http://example.com/2022/09/26/JDK19/"/>
    <id>http://example.com/2022/09/26/JDK19/</id>
    <published>2022-09-26T11:47:43.000Z</published>
    <updated>2022-09-26T12:03:52.263Z</updated>
    
    <content type="html"><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>JDK19于2022-09-20发布GA版本。是一个非LTS版本，将以结构化并发、虚拟线程、切换表达模式匹配、向量API和Linux&#x2F;RISC-V端口为特色</p><p>JDK 19的早期访问版本可以从JDK.java.net&#x2F;19访问。JDK 19功能包括：</p><ul><li>在孵化器阶段，结构化并发旨在通过结构化并发API简化多线程编程。这种并发性将在不同线程中运行的多个任务视为单个工作单元，以简化错误处理和取消。提高了可靠性和可观测性。</li><li>记录模式record的预览，用于解构record记录值。记录模式和类型模式可以嵌套，以实现声明性、强大且可组合的数据导航和处理形式。该提案的目标包括扩展模式匹配以表达更复杂、可组合的数据查询，同时不改变类型模式的语法或语义。该提案以 instanceof 的模式匹配为基础，于2021在JDK 16中交付。未来的计划可能要求使用阵列模式和 vararg 模式等功能扩展记录模式。记录模式是Amber项目的一部分，该项目旨在探索和培育更小的、面向生产力的Java特性。</li><li>一个外部函数和内存API的预览，它将引入一个API，通过该API，Java程序可以与Java运行时之外的代码和数据进行互操作。通过有效地调用外部函数（即JVM外部的代码）和安全地访问外部内存（即未由JVM管理的内存），API使Java程序能够调用本机库并处理本机数据，而不会出现Java本机接口（ JNI ）的危险和脆弱性。外部函数和内存API结合了两个早期的孵化API：外部内存访问API和外部链接器API。外部函数和内存API之前在JDK 17中孵化，并在JDK 18中重新计算。该提案的目标包括易用性、性能、通用性和安全性。</li><li>虚拟线程的预览，这是一种轻量级线程，可以显著减少编写、维护和观察高吞吐量并发应用程序的工作量。目标包括使以简单的请求线程风格编写的服务器应用程序能够以接近最佳的硬件利用率进行扩展，并启用使用java的现有代码java.lang Thread API以最小的变化采用虚拟线程，并使用现有JDK工具对虚拟线程进行故障排除、调试和评测。本提案的目标不是改变Java中的基本并发模型，也不是在Java语言或Java库中提供新的数据并行结构。删除线程的传统实现或静默地将现有应用程序迁移到虚拟线程也不是目标。</li><li>switch 表达式和语句模式匹配的第三个预览，将模式匹配扩展到 switch ，允许针对多个模式测试表达式，每个模式都有一个特定的操作，因此可以简洁安全地表达复杂的面向数据的查询。此功能以前在JDK 17和JDK 18中进行了预览。第三次预览将添加一些改进，包括在开关块中用when子句替换受保护的模式。此外，当选择器表达式的值为null时，模式开关的运行时语义与传统开关语义更加一致。该计划的目标包括通过允许模式出现在 case 标签中，扩展switch表达式和语句的表达能力和适用性。其他目标包括允许开发人员在需要时放松 switch 的历史性零敌意，提高 switch 语句的安全性，并确保现有的 switch 表达式和语句继续编译而不发生更改，并以相同的语义执行。</li><li>第四种是vector 矢量API，它将矢量计算表示为在运行时可靠编译为支持的CPU架构上的最优矢量指令，从而实现优于等效标量计算的性能。使用API的开发人员获得了一种用Java编写复杂向量算法的方法，使用了热点自动向量器，但用户模型使向量化更加可预测和健壮。之前将载体API培养到JDK 16、JDK 17和JDK 19中。</li><li>对JDK 19提出的API的改进包括增强了向MemorySegment加载和存储向量，这是由外部函数和内存API预览定义的。JDK 19还将添加两个交叉车道矢量操作，压缩和扩展，以及互补矢量掩码压缩操作。压缩向量操作将由掩码选择的源向量的车道按车道顺序映射到目标向量，而展开操作则相反。压缩操作在过滤查询结果时很有用。除了矢量API之外，还将扩展逐位积分lanewise操作，包括计算一位的数量、反转位的顺序以及压缩和扩展位等操作。API的目标包括简洁明了、不依赖平台、在x64和AArch64体系结构上具有可靠的运行时和编译性能，以及在向量计算无法在运行时完全表示为向量操作序列的情况下实现“优雅”降级。</li><li>通过Linux&#x2F;RISC-V端口，Java将获得对硬件指令集的支持，这种硬件指令集已经得到了各种语言工具链的支持。RISC-V实际上是一个相关ISA家族。Linux&#x2F;RISC-V端口将仅支持RISC-V的RV64GV配置，这是一种包含矢量指令的通用64位ISA。Java开发人员将来可能会考虑其他RISC-V配置。</li></ul><h1 id="虚拟线程"><a href="#虚拟线程" class="headerlink" title="虚拟线程"></a>虚拟线程</h1><h2 id="Java线程与虚拟线程"><a href="#Java线程与虚拟线程" class="headerlink" title="Java线程与虚拟线程"></a>Java线程与虚拟线程</h2><p>常用的java线程与系统内核线程是一一对应的，系统内核的线程调度程序负载调度java线程。为了增加应用程序的性能，我们会增加java线程，所以在调度java线程的时候会占据不少资源去处理线程的上下文切换。</p><p>提高系统的吞吐量，就增加线程数量，但机器的线程昂贵、可用线程有限，即使是使用了线程池来最大化线程的性价比，但CPU、网络或内存资源还是程序性能的瓶颈。于是JDK19引入了虚拟线程，在19中，之前常用的平台线程与系统内核线程还是一一对应。</p><h2 id="新增线程相关API"><a href="#新增线程相关API" class="headerlink" title="新增线程相关API"></a>新增线程相关API</h2><p><code>Thread.ofVirtual()和Thread.ofPlatform()</code>是创建虚拟和平台线程的新API</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//输出线程ID 包括虚拟线程和系统线程 Thread.getId() 从jdk19废弃</span></span><br><span class="line"><span class="type">Runnable</span> <span class="variable">runnable</span> <span class="operator">=</span> () -&gt; System.out.println(Thread.currentThread().threadId());</span><br><span class="line"><span class="comment">//创建虚拟线程</span></span><br><span class="line"><span class="type">Thread</span> <span class="variable">thread</span> <span class="operator">=</span> Thread.ofVirtual().name(<span class="string">&quot;testVT&quot;</span>).unstarted(runnable);</span><br><span class="line">testVT.start();</span><br><span class="line"><span class="comment">//创建虚平台线程</span></span><br><span class="line"><span class="type">Thread</span> <span class="variable">testPT</span> <span class="operator">=</span> Thread.ofPlatform().name(<span class="string">&quot;testPT&quot;</span>).unstarted(runnable);</span><br><span class="line">testPT.start();</span><br></pre></td></tr></table></figure><p><code>Thread.startVirtualThread(Runnable)</code>快速创建虚拟线程并启动</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//输出线程ID 包括虚拟线程和系统线程</span></span><br><span class="line"><span class="type">Runnable</span> <span class="variable">runnable</span> <span class="operator">=</span> () -&gt; System.out.println(Thread.currentThread().threadId());</span><br><span class="line"><span class="type">Thread</span> <span class="variable">thread</span> <span class="operator">=</span> Thread.startVirtualThread(runnable);</span><br></pre></td></tr></table></figure><p><code>Thread.isVirtual()</code> 判断线程是否为虚拟线程：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//输出线程ID 包括虚拟线程和系统线程</span></span><br><span class="line"><span class="type">Runnable</span> <span class="variable">runnable</span> <span class="operator">=</span> () -&gt; System.out.println(Thread.currentThread().isVirtual());</span><br><span class="line"><span class="type">Thread</span> <span class="variable">thread</span> <span class="operator">=</span> Thread.startVirtualThread(runnable);</span><br></pre></td></tr></table></figure><p><code>Thread.join</code> 和 <code>Thread.sleep</code> 等待虚拟线程结束、使虚拟线程 sleep：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Runnable</span> <span class="variable">runnable</span> <span class="operator">=</span> () -&gt; System.out.println(Thread.sleep(<span class="number">10</span>));</span><br><span class="line"><span class="type">Thread</span> <span class="variable">thread</span> <span class="operator">=</span> Thread.startVirtualThread(runnable);</span><br><span class="line"><span class="comment">//等待虚拟线程结束</span></span><br><span class="line">thread.join();</span><br></pre></td></tr></table></figure><p><code>Executors.newVirtualThreadPerTaskExecutor()</code> 创建一个 ExecutorService，该 ExecutorService 为每个任务创建一个新的虚拟线程</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span> (<span class="type">var</span> <span class="variable">executor</span> <span class="operator">=</span> Executors.newVirtualThreadPerTaskExecutor()) &#123;</span><br><span class="line">  executor.submit(() -&gt; System.out.println(<span class="string">&quot;hello&quot;</span>));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>支持与使用线程池和ExecutorService 的现有代码互相替换、迁移。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h1&gt;&lt;p&gt;JDK19于2022-09-20发布GA版本。是一个非LTS版本，将以结构化并发、虚拟线程、切换表达模式匹配、向量API和Linux&amp;#x2</summary>
      
    
    
    
    <category term="基础" scheme="http://example.com/categories/%E5%9F%BA%E7%A1%80/"/>
    
    
    <category term="JDK" scheme="http://example.com/tags/JDK/"/>
    
  </entry>
  
  <entry>
    <title>Kafka可靠性</title>
    <link href="http://example.com/2022/09/25/Kafka%E5%8F%AF%E9%9D%A0%E6%80%A7/"/>
    <id>http://example.com/2022/09/25/Kafka%E5%8F%AF%E9%9D%A0%E6%80%A7/</id>
    <published>2022-09-25T08:51:00.000Z</published>
    <updated>2022-09-25T08:55:25.666Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Kafka可靠性简述"><a href="#Kafka可靠性简述" class="headerlink" title="Kafka可靠性简述"></a>Kafka可靠性简述</h1><p>Kafka<em><strong>采用了多副本的机制</strong></em>，也是大多分布式系统中惯用收发，以实现水平拓展、提供容灾能力、提升可用性和可靠性。</p><h1 id="副本剖析"><a href="#副本剖析" class="headerlink" title="副本剖析"></a>副本剖析</h1><p>副本是分布式系统常见的概念之一，是分布式系统对数据和服务提供的一种冗余方式。<em><strong>数据副本</strong></em>是在不同的节点上持久化同一份数据，当某一个节点上存储的数据丢失时，可以从副本上读取该数据，是解决分布式系统数据源丢失问题的最有效的手段。另一类副本是<em><strong>服务副本</strong></em>，指多个节点提供同样的服务，每个节点都有能力接收来自外部请求并进行相应的处理。</p><p>Kafka引入多副本机制，增加副本数量提升数据容灾能力；多副本也实现故障自动转移，在某个broekr节点失效时候仍然保证服务可用。</p><ul><li>副本是相对于分区而言，副本是特定分区的副本。</li><li>一个分区中包含一个或多个副本，其中一个为leader副本，其余为follower副本，各个副本位于不同的broker节点。只有leader副本提供服务，follower副本只负责数据同步。</li><li>分区所有副本统称为AR，ISR是值与leader副本保持同步状态的副本集合，leader副本本身也是该集合中的一个。</li><li>LEO标识每个分区中最后一条消息的下一个位置，分区的每个副本都有自己的LEO，ISR中最小的LEO即为HW，俗称高水位，消费者只能拉取到HW之前的消息。</li></ul><p>从生产者发出的一条消息首先会被分区写入leader副本，不过需要等待ISR集合中的所有follower副本都同步完成后才能为认为是已提交，之后才会更新分区的HW，进而消费者可以消费到该消息</p><h2 id="副本失效"><a href="#副本失效" class="headerlink" title="副本失效"></a>副本失效</h2><p>正常情况下，分区的所有副本都是在ISR集合中，当出现异常情况某些副本就被剥离出ISR集合中。在ISR集合中，也就是处于同步失效或功能失效的副本称为失效副本，失效副本对应的分区称为同步失效分区。</p><p>失效副本不仅是指处于功能失效状态的副本，处于同步失效状态的副本也可看做失效副本。</p><p>典型情况：当leader副本中消息的流入速度比foloower副本拉取速度快，follower副本一直拉也不能与leader副本同步，若follower副本还在ISR集合中，那在leader副本下线而选取此follower副本为新的leader副本时会造成消息的严重丢失</p><p>会导致副本失效的一般情况：</p><ul><li>follower副本进程卡住，在一段时间内没有向leader副本发起同步请求。比如频繁的Full GC</li><li>follower副本进程同步太慢，在一段时间内无法追赶上leader副本。比如I&#x2F;O开销太大</li></ul><h2 id="ISR伸缩"><a href="#ISR伸缩" class="headerlink" title="ISR伸缩"></a>ISR伸缩</h2><p>Kafka启动的时候会开启两个与ISR相关的定时任务</p><ul><li>“isr-expiration”定时任务：会周期性地检测每个分区是否需要缩减其ISR集合。该周期为replica.lag.time.max.ms参数大小的一半，默认值是5000ms。当检测到ISR集合中有失效副本时，就会收缩ISR集合。若某个分区的ISR集合变更，就将变更后的数据记录到ZK中。</li><li>“isr-change-propagation”定时任务：会周期性的检查isrChangeSet，若发现其有ISR集合的变更记录，就会在ZK的路径下创建一个以isr_change_开头的持久顺序节点，并isrChangeSet中的信息保存到该节点中；Kafka为该定时任务添加了一个watcher，当该节点中有子节点发生变化时会触发watcher的动作，以此通知控制器更新相关元数据信息并向它管理的broker节点发送更新元数据的请求，最后删除已处理过的节点信息。当然，若频繁触发watcher会影响性能，所以添加了限定条件，当检测到分区的ISR集合发生变化时需要检测：上一次ISR集合发生变化的时间间隔已经超过5s、上一次写入ZK的时间间隔已超过60s，满足两者之一才可以将ISR集合写入目标节点；</li></ul><p>随着follower副本同步消息，follower副本的LEO会逐渐后移，并追赶上leader副本（追赶的标准是此副本的LEO是否不小于leader副本的HW），此时该follower副本就有资格进入ISR集合。</p><h2 id="LEO和HW"><a href="#LEO和HW" class="headerlink" title="LEO和HW"></a>LEO和HW</h2><p>本地副本：对应的Log分配在当前的broker节点上。远程副本：对应的Log分配在其他的broker节点上。</p><p>Kafka中，同一个分区的信息会存在多个broker节点上，并被其上的副本管理器所管理，在逻辑层面每个broker节点上的分区就有了多个副本，但唯有本地副本才有对应的日志</p><p>在一个分区中，leader副本所在的节点会记录所有副本的LEO，follower副本所在的节点只会记录自身的LEO。各个副本所在的节点都只记录自身的HW。</p><h2 id="不支持读写分离"><a href="#不支持读写分离" class="headerlink" title="不支持读写分离"></a>不支持读写分离</h2><p>Kafka中，生产者写入消息、消费者读取消息都是与leader副本进行交互，实现的是主写主读的生产消费模型，<em><strong>且不支持读写分离</strong></em>。而数据库、Redis都具备主写主读功能、也支持主写从读（读写分离）。</p><p>读写分离的缺点：</p><ul><li>数据一致性问题：数据从主节点到从节点必有一个延时的时间窗口，该窗口会导致主从节点之间的数据不一致。</li><li>延时问题：类似Redis该类的组件，数据从写入主节点到同步到从节点的过程都要经过 网络-主节点内存-网络-从节点内存，整个过程比较耗时。而Kafka中主从同步会更耗时，网络-主节点内存-主节点磁盘-网络-从节点内存-从节点内存-从节点磁盘。对延时敏感的情况，主从功能就不适用</li></ul><p>主读从写可以均摊一定的负载却不能做到完全的负载均衡。Kafka可以大程度负载均衡</p><p>主写主读的优点：</p><ul><li>简化代码的实现逻辑，减少出错的可能</li><li>负载粒度细化均摊，与主写从读相比，负载更好且对用户可控</li><li>没有延时的影响</li><li>副本稳定的情况下，不会出现数据不一致的情况</li></ul><h1 id="日志同步机制"><a href="#日志同步机制" class="headerlink" title="日志同步机制"></a>日志同步机制</h1><p>分布式系统中，日志同步机制<em><strong>需要保证数据一致性、数据的顺序性</strong></em>，最简单高效的方法是从集群中选出一个leader来负责处理数据写入的顺序性，只要leader活着，follower就根据leader写入顺序进行同步。</p><p>但是当leader宕机后，follower中就会选出一个新的leader。follower同步状态可能落后leader很多，甚至可能还是宕机的，所以要确保<em><strong>选择具有最新日志消息的follower作为新leader</strong></em>。</p><p>日志同步机制的一个基本原则：若告知客户端已成功提交某条消息，那么即使leader宕机，也要保证新选举出的leader中能包含这条消息。这里就有权衡的地方，若leader在消息被提交前需要等更多follower确认，那么在它宕机后就可以找到follower的替代，虽然这样性能会下降。</p><p>Kafka选举不采用常见的“少数服从多数”。采用该方式，系统的延迟取决于最快的几个节点，但是为了保证leader选举的正常运行那么能容忍的失败follower数也就少，也就是要保证较高的容错率，必须要有大量副本，也正因为大量性能就会下降。</p><p>Kafka使用的是PacificA算法。Kafka动态维护着一个ISR集合，处于ISR集合内的节点保持与leader相同的高水位，只有位列其中的副本才有资格成为leader。写入消息只有所有ISR集合中的副本都确认收到后才能被认为已提交；位于ISR集合的任何副本节点都有资格成为leader，选举过程简单，开销低。leader副本的均衡保证了整体负载的均衡</p><h1 id="可靠性分析"><a href="#可靠性分析" class="headerlink" title="可靠性分析"></a>可靠性分析</h1><p>就Kafka而言，越多的副本数（在创建主题时配置也可后期修改）能保证数据的可靠性，但太多也会引起磁盘、网络带宽的浪费，性能才会下降。</p><p>生产者客户端参数ack可以提高消息的可靠性。</p><ul><li>1（默认）：生产者发送消息后，分区的leader副本成功写入就可以收到来自服务端的成功响应。若无法写入leader副本，生产者就会收到错误响应，此时可以重发消息</li><li>0：生产者发完消息不需要等待服务端的响应。消息会丢失，但可以达到最大吞吐量</li><li>-1或all：生产者发送后，需要等待所有ISR集合中所有副本都成功写入消息后才能收到响应成功。能达到最强的可靠性，但不意味着消息一定可靠，因为ISR中可能只有leader副本。</li></ul><p>broker端有两个参数可以调整同步刷盘的策略。同步刷盘是增加可靠性的方式，但是及其消耗性能。</p><p>手动位移提交也是一种方式，但有一个原则：若消息没有被成功消息，那么久不能提交所对应的消费位移。宁愿重复消费也不能因异常而消息丢失</p><p>消费端，Kafka提供了<em><strong>回溯消费</strong></em>功能来兜底，有机会对漏掉的消息进行回补，提高可靠性</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Kafka可靠性简述&quot;&gt;&lt;a href=&quot;#Kafka可靠性简述&quot; class=&quot;headerlink&quot; title=&quot;Kafka可靠性简述&quot;&gt;&lt;/a&gt;Kafka可靠性简述&lt;/h1&gt;&lt;p&gt;Kafka&lt;em&gt;&lt;strong&gt;采用了多副本的机制&lt;/strong&gt;&lt;/e</summary>
      
    
    
    
    <category term="消息队列" scheme="http://example.com/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
    <category term="Kafka" scheme="http://example.com/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>Kafka客户端</title>
    <link href="http://example.com/2022/09/19/Kafka%E5%AE%A2%E6%88%B7%E7%AB%AF/"/>
    <id>http://example.com/2022/09/19/Kafka%E5%AE%A2%E6%88%B7%E7%AB%AF/</id>
    <published>2022-09-19T15:32:45.000Z</published>
    <updated>2022-09-20T11:52:46.760Z</updated>
    
    <content type="html"><![CDATA[<p>客户端是需要与服务端交互</p><h1 id="分区分配策略"><a href="#分区分配策略" class="headerlink" title="分区分配策略"></a>分区分配策略</h1><p>Kafka提供了消费者客户端参数partition.assignment.strategy设置消费者与订阅主题之间的分区分配策略。Kafka提供了三种分配策略</p><ul><li>RangeAssignor分配策略：按照消费者总数和分区总数进行整除运算来获得一个跨度，然后将分区按照跨度进行平均分配，以保证分区尽可能均匀的分配给所有的消费者。对于每个主题，该策略会将消费组内所有订阅这个主题的消费者按照名称的字典排序，然后每个消费者划分固定的分区范围，若不够平均，字典序考前的会被多分一个。该情况可能出现部分消费者过载的情况。</li><li>RoudRobinAssignor分配策略：将消费组内所有消费者及消费者订阅的所有主题的分区按照字典序排序，再以轮询方式逐个将分区依次分配给每个消费者。若同一个消费组内所有的消费者的订阅消息相同，那么该策略的分区分配是平均的；若同一消费组内消费者订阅的消息不同，那么在执行分区分配就不是完全的轮询分配，有可能导致分区分配不均匀。若某消费者没有订阅消费组内的某个主题，那在分配分区的时候该消费者就分配不到该主题的任何分区。</li><li>StickyAssignor分配策略：主要有两个目的：分区的分配要尽可能均匀；分区的分配尽可能与上次分配相同。前者优先级更高。优点就是可以让分区具备“黏性”，减少不必要的分区移动（即一个分区剥离之前的消费者，转而分配给另一个新的消费者）</li></ul><p>除了Kafka提供的，还可以自定义实现分配策略。</p><h1 id="消费者协调器和组协调器"><a href="#消费者协调器和组协调器" class="headerlink" title="消费者协调器和组协调器"></a>消费者协调器和组协调器</h1><p>消费者协调器和组协调器是针对新版的消费者客户端。旧版的消费者客户端是使用ZK的监听器实现功能。</p><p>每个消费组在ZK中维护了一个&#x2F;consumers&#x2F;<group>&#x2F;ids路径，该路径下的记录都是消费组中的消费者的唯一标识id，consumerIdString由消费者启动时创建。</group></p><p>每个broker、主题和分区在ZK中也都对应的一个路径，不同的路径下记录着不同的信息</p><p>每个消费者在启动时会在两个路径上主题一个监听器。当consumer&#x2F;<group>&#x2F;ids路径下的子节点变化，表示消费组中的消费者发生变化；当&#x2F;broker&#x2F;ids路径下的子节点发生变化，表示broker出现增减。这样通过ZK所提供的Watcher，每个消费者都可以监听减肥族和Kafka集群的状态。</group></p><p>该方式下每个消费者对ZK的相关路径分别进行监听，当触发再均衡操作时，一个消费组下所有消费者会同时再均衡，而消费者之间互相不了解彼此的操作，就可能导致Kafka工作在错误状态。</p><p>严重依赖ZK集群的后果：</p><ul><li>羊群效应：ZK中一个被监听的节点变化，大量Watcher通过被发送到客户端，导致通知期间的其他操作延迟，有可能死锁</li><li>脑裂问题：消费者再均衡操作时，每个消费者都与ZK进行通信以判断消费者或broker变化情况，由于ZK本身特性，可能让同一时刻各个消费者获取的状态不同，就会有异常</li></ul><h1 id="再均衡原理"><a href="#再均衡原理" class="headerlink" title="再均衡原理"></a>再均衡原理</h1><p>新版的消费者客户端对此进行了重新设计，将全部消费组分成多个子集，每个消费组的子集在服务端对应一个GroupCoordinator（Kafka服务端中管理消费组的组件）对其管理。</p><p>触发再均衡操作的场景：</p><ul><li>新的消费者加入消费组</li><li>有消费者宕机下线。消费者不一定真正下线，可能是长时间GC、网络延迟而未发送心跳等等</li><li>消费者主动退出消费组。比如：客户端调用了方法以取消对某些主题的订阅</li><li>消费组所对应的GroupCoorinator节点变更</li><li>消费组内所订阅的任一主题或主题的分区数量变化</li></ul><p> 举例：</p><ul><li>消费者确定它所属消费组对应的GroupCoordinator所在的broekr并创建与该broker相互通信的网络连接。若消费者保留了对应的GroupCoordinator节点信息且与它之间的网络连接正常，就下一步；反之，就需要向集群中的负载最小的节点发送请求查找对应的GroupCoordinator。</li><li>找到消费组对应的GroupCoordinator后，消费者向GroupCoordinator发送请求并处理响应。若是原有消费者重新加入消费组，则在发送请求前还要做一些准备（可能开启自动提交位移功能，所以要提交消费位移；可能添加自定义的再均衡监听器，那就要清楚一些状态；因为是重新加入消费组，所以加入前要禁止心跳检测的运行）；&#x3D;&#x3D;选举消费组的leader&#x3D;&#x3D;：总体很随意，若组内还没有就选第一个加入组的消费者，若leader退出就随机选（HashMap存储消费者信息，随机的形式取出一key选）；&#x3D;&#x3D;选举分区分配策略&#x3D;&#x3D;：每个消费者都可设自己的分区分配策略，所以整个组需要各个消费者的投票决定。大致过程：收集各个消费者支持的策略，组成候选集，每个消费者从候选集中找出支持的投一票，选票最多的；</li><li>实施上一阶段决定的分区策略，之后需要将分配方案同步给各个消费者</li><li>该阶段消费组中所有消费者就处于工作状态。正式消费前，消费者要确定拉取消息的起始位置。消费者向GroupCoordinator发送心跳维持它们与消费组的从属关系以及对分区的所有权关系（心跳线程独立，可以在轮询消息的空档发）。若一消费者崩溃并停止读消息，GroupCoordinator会等待一会儿以确认其死亡再触发再均衡，等待期间不会读取分区里的消息</li></ul><h1 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h1><p>消息中间件的传输消息传输保障</p><ul><li>at most once： 至多一次。消息可能会丢失，但绝对不会重复传输。</li><li>at least once：最少一次。消息绝对不会丢失，但可能会重复传输（Kafka）</li><li>exactly once：恰好一次。每条消息肯定会被传输一次且仅传输一次</li></ul><p>当生产者向Kafka发消息，一旦被成功提交日志文件，由于多副本机制存在，该消息就不会丢失。若发送到Kafka之后，因网络问题而通信中断，生产者就不能判断消息是否已提交，所以生产者可以多次重试以确保提交到Kafka，但也可能造成消息重复写入。</p><ul><li>对于消费者，消费者处理消息和提交消费位移的顺序在很大程度决定了消费者提供哪一种消息传输保障。若消费者拉取消息后，应用逻辑先处理消息后提交消费位移，那么在消费处理后且在位移提交前消费者宕机了，待它重新上限后，会从上一次位移提交的位置拉取，就出现了重复消费。对应at least once</li><li>对于消费者，若消费者在拉完消息后，应用逻辑先提交消费位移再进行消息处理，那么在位移提交后且在消息处理完成前消费者宕机，重新上线后，会从已经提交的位移处开始消费，但是之前有部分消息没有被消费，就造成消息丢失。对应at most once</li></ul><p>于是，Kafka引入幂等和事务两个特性</p><p>幂等：简单说就是<em><strong>对接口的多次调用所产生的结果和调用一次是一致的</strong></em>。生产者在进行重试的时候可能会重复写入消息，使用Kafka的幂等性功能后可以避免该情况。不能跨多个分区运作</p><p>事务：可以弥补跨多个分区运作的缺陷。<em><strong>保证对多个分区写入操作的原子性</strong></em>。为了实现事务，应用程序必须提供唯一的transactionalId，该值通过客户端参数transactional.id设置。能保证的语义相对偏弱。</p><p>Kafka不能保证已提交的事务中的所有消息都能被消费的原因：</p><ul><li>对采用日志压缩策略的主题，事务中的某些消息可能被清理。（相同的key，前写入的消息被后面的覆盖）</li><li>事务中消息可能分布在同一个分区的多个日志分段中，老的日志分段被删除时，对应的消息可能丢失</li><li>消费者可以通过seek()方法访问任意offset消息，从而可能遗漏事务中的部分消息</li><li>消费者在消费时可能没有分配到事务内的所有分区，就不能读取事务中的所有消息</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;客户端是需要与服务端交互&lt;/p&gt;
&lt;h1 id=&quot;分区分配策略&quot;&gt;&lt;a href=&quot;#分区分配策略&quot; class=&quot;headerlink&quot; title=&quot;分区分配策略&quot;&gt;&lt;/a&gt;分区分配策略&lt;/h1&gt;&lt;p&gt;Kafka提供了消费者客户端参数partition.assignme</summary>
      
    
    
    
    <category term="消息队列" scheme="http://example.com/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
    <category term="Kafka" scheme="http://example.com/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>Kafka服务端</title>
    <link href="http://example.com/2022/09/17/Kafka%E6%9C%8D%E5%8A%A1%E7%AB%AF/"/>
    <id>http://example.com/2022/09/17/Kafka%E6%9C%8D%E5%8A%A1%E7%AB%AF/</id>
    <published>2022-09-16T20:33:33.000Z</published>
    <updated>2022-09-16T20:39:45.958Z</updated>
    
    <content type="html"><![CDATA[<h1 id="协议设计"><a href="#协议设计" class="headerlink" title="协议设计"></a>协议设计</h1><p>自定义了一组<em><strong>基于TCP的二进制</strong></em>协议，遵守该组协议的格式，就可以向Kafka发送消息、拉取消息。</p><p>在Kafka2.0中，共43种协议类型，每种协议类型都有对应的请求和响应，都遵守特定的协议模式。每种类型的Request都包含相同结构的协议请求头和不同结构的协议请求体。</p><ul><li>协议请求头</li></ul><p><img src="/2022/09/17/Kafka%E6%9C%8D%E5%8A%A1%E7%AB%AF/qingqiutou.png"></p><table><thead><tr><th align="center">域</th><th align="center">描述</th></tr></thead><tbody><tr><td align="center">api_key</td><td align="center">API标识，</td></tr><tr><td align="center">api_version</td><td align="center">API版本号</td></tr><tr><td align="center">correlation_id</td><td align="center">由客户端指定的一个数字来唯一标识此次请求的id，服务端在处理完请求后也把相同的coorelation_id写到Response中。如此，客户端就能把某个请求和响应对应</td></tr><tr><td align="center">client_id</td><td align="center">客户端id</td></tr></tbody></table><ul><li>协议响应头</li></ul><p>每种类型的Response也包含相同结构的协议响应头和不同结构的响应体</p><p><img src="/2022/09/17/Kafka%E6%9C%8D%E5%8A%A1%E7%AB%AF/xiangyingtou.png"></p><h1 id="时间轮"><a href="#时间轮" class="headerlink" title="时间轮"></a>时间轮</h1><p>Kafka中存在大量的延时操作（延时生产、延时拉取、延时删除等等），没有使用JDK自带的Timer或DelayQueue以实现延时功能，而是使用基于时间轮的概念实现了<em><strong>用于延时功能的定时器</strong></em>。</p><p>时间轮由多个时间格组成，每个时间格代表当前轮的基本时间跨度。时间格个数固定，整个时间轮的总体跨度不变</p><p><img src="/2022/09/17/Kafka%E6%9C%8D%E5%8A%A1%E7%AB%AF/shijianlun.png"></p><p>时间轮的轮转是靠“收割机”线程驱动，由延时操作管理器启动。“收割机”线程还会定期清理监听池中已完成的延时操作。</p><h1 id="延时操作"><a href="#延时操作" class="headerlink" title="延时操作"></a>延时操作</h1><p>若生产者客户端发消息时将acks参数设置为-1，那么久需要等待ISR集合中所有副本都确认收到消息后才能收到响应的结果或捕获超时异常。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">比如：某个分区有三个副本leader1、follower1、follower2且都在ISR集合中，Kafka在收到客户端生产请求后，消息3和4写入leader副本的本地日志文件后，需要等到follower1和follower2两个副本都收到消息3和4后才能告知客户端正确地接收了所发送的消息，若超时则抛异常。此处，在消息写入leader副本的本地日志文件后，Kafka会创建一个延时的生产操作来处理消息正常写入所有副本或超时情况，以返回相应的响应结果给客户端。</span><br></pre></td></tr></table></figure><p>Kafka有多个延时操作，需要延时返回响应结果，首先就要有超时时间，超时就要强制完成以响应结果；其次延时不同于定时操作，定时操作是在特定时间后执行的操作，延时操作可以在设定的时间之前完成，于是&#x3D;&#x3D;延时操作能支持外部事件的触发&#x3D;&#x3D;。</p><p>延时操作创建后会被加入延时操作管理器做专门的处理，延时操作可能超时，每个延时操作管理器都会配备一个定时器做超时管理，定时器的底层就是用的时间轮。因为需要支持外部事件，所以还配备一个监听池来监听每个分区的外部事件（查看是否有分区的HW增长）</p><p>而对于延时拉取，Kafka会先读取一次日志文件，若收集不到足够多的消息，就会创建一个延时拉取操作以等待拉取到足够数量的消息。当延时拉取操作执行时，会再读一次日志文件，再将拉取结果返回给follower副本。延时拉取操作也会有专门的延时操作管理器负载，与上述相同。若拉取进度一直没有赶上leader副本，那么在拉取laeader副本的消息时一般拉取的消息大小会不小于某个值，这样Kafka不会创建延时操作，而是直接返回拉取结果。</p><h1 id="控制器"><a href="#控制器" class="headerlink" title="控制器"></a>控制器</h1><p>Kafka集群中会有一个或多个broker，其中一个 broker会被选为控制器，负责管理整个集群中所有分区和副本的状态。当某个leader副本有问题，由控制器负载该分区选举新的leader副本；当检测当某个分区的ISR集合发生变化，由控制器通知所有broker更新其元数据信息；为某个topic增加分区数量时负责分区的重新分配</p><p>Kafka中控制器选举依赖于ZooKeeper，成功竞选的broker会在ZK中创建&#x2F;controller这个临时节点。</p><p>具备控制器身份的broker会比其他普通的broker多一些作用</p><ul><li>监听分区的变化</li><li>监听主题相关的变化</li><li>监听broker相关的变化</li><li>从ZK中读取获取当前所有与主题、分区及broker有关信息并进行相应管理</li><li>启动并管理分区状态机和副本状态机</li><li>更新集群元数据信息</li><li>若参数auto.leader.rebalance.enable设置为true，则会开启一个定时任务维护分区的优先副本均衡</li></ul><p>控制器选举成功后会读取ZK中各节点的数据来初始化上下文信息，并管理。</p><p>控制器节点数据发生变化，每个broekr都会更新自身内存中保存的activeControllerId，若broker在数据变更前是控制器，在数据变更后自身的brokerid值与新的activeControllerId值不同，那就关闭相关的资源。</p><p>控制器节点被删除时，每个broekr会开始选举。</p><p>分区leader副本的选举由控制器负责。当创建分区或分区上线的时候都需要leader选举。对应的策略是按照AR集合中副本的顺序查找第一个存活的副本并且该副本在ISR集合中。</p><h1 id="两个参数"><a href="#两个参数" class="headerlink" title="两个参数"></a>两个参数</h1><table><thead><tr><th align="left">参数</th><th align="center">说明</th></tr></thead><tbody><tr><td align="left">broker.id</td><td align="center">broekr启动之前就必须设定的，每个broker都有的唯一id值用来区分，启动时会在ZK中&#x2F;brokers&#x2F;ids路径下创建以brokerid为名称的节点。当broker下线，该虚节点会自动删除，其他节点或客户端就通过路径下是否有该brokerid来确定健康状态。</td></tr><tr><td align="left">bootstrap.servers</td><td align="center">生产者和消费者君必备的。一般可简单认为是指定将要连接的Kafka集群的broker地址列表。深层意义是Kafka集群元数据信息的服务地址</td></tr></tbody></table>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;协议设计&quot;&gt;&lt;a href=&quot;#协议设计&quot; class=&quot;headerlink&quot; title=&quot;协议设计&quot;&gt;&lt;/a&gt;协议设计&lt;/h1&gt;&lt;p&gt;自定义了一组&lt;em&gt;&lt;strong&gt;基于TCP的二进制&lt;/strong&gt;&lt;/em&gt;协议，遵守该组协议的格式，就可以向Kafk</summary>
      
    
    
    
    <category term="消息队列" scheme="http://example.com/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
    <category term="Kafka" scheme="http://example.com/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>Kafka日志存储</title>
    <link href="http://example.com/2022/09/13/Kafka%E6%97%A5%E5%BF%97%E5%AD%98%E5%82%A8/"/>
    <id>http://example.com/2022/09/13/Kafka%E6%97%A5%E5%BF%97%E5%AD%98%E5%82%A8/</id>
    <published>2022-09-13T14:59:44.000Z</published>
    <updated>2022-09-13T17:08:32.714Z</updated>
    
    <content type="html"><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>若分区规则合理，那么所有的消息可以均匀的分布到不同的分区中，可以实现水平拓展。不考虑多副本的情况，一个分区对应一个日志。为防止log太大，所以Kafka引入了日志分段的概念：Log切分成多个LogSegment，相当于一个巨型文件被平均分配为多个较小的文件，这样也便于清理和维护。</p><p><img src="/2022/09/13/Kafka%E6%97%A5%E5%BF%97%E5%AD%98%E5%82%A8/jiegou.png"></p><p>向Log中追加消息是顺序写入，只有最后一个LogSegment才能执行写操作，在此之前所有的LogSegment都不能写入数据。一直往最后一个LogSegment写入消息，当满足一定的条件后就需要创建新的LogSegment。</p><p><em><strong>为了便于消息的检索</strong></em>，每个LogSegment中的日志文件都有对应的两个索引文件：偏移量索引文件和时间戳索引文件。每个LogSegment都有一个基准偏移量baseOffset（表示当前LogSegment中第一条消息的offset），两个索引文件都是基于该偏移量命名。</p><p><strong>生产者发送的压缩数据在broker中也是压缩状态进行存储</strong>*</p><h1 id="日志索引"><a href="#日志索引" class="headerlink" title="日志索引"></a>日志索引</h1><ul><li>偏移量索引文件用来建立<em><strong>消息偏移量到物理地址之间的映射关系</strong></em>，方便快速定位消息所在的物理文件位置</li><li>时间戳索引文件是根据指定的<em><strong>时间戳来查找对应的偏移量信息</strong></em>。</li></ul><p>Kafka中的索引文件以<em><strong>稀疏索引</strong></em>的方式构造消息的索引，不保证每个消息在索引文件中都有对应的索引项。每写入一定量的消息，偏移量索引文件和时间戳索引文件分别增加一个偏移量索引项和时间戳索引项的。稀疏索引将索引索引文件映射到内存中，以加快查询的速度。偏移量索引文件中偏移量是单调递增，查询指定偏移量是使用二分查找法来定位偏移量的位置；时间戳索引文件中的时间戳也是单调递增，也是二分法查找不大于该时间戳的最大偏移量，但寻找相应的物理文件位置需要根据偏移量索引文件定位。</p><h2 id="偏移量索引"><a href="#偏移量索引" class="headerlink" title="偏移量索引"></a>偏移量索引</h2><p>偏移量索引文件格式，每项索引项占用8个字节</p><p><img src="/2022/09/13/Kafka%E6%97%A5%E5%BF%97%E5%AD%98%E5%82%A8/pianyiliang.png"></p><ul><li>relativeOffset：相对偏移量，表示消息相对于baseOffset的偏移量，占4个字节，当前索引文件的文件名即为baseOffset的值</li><li>position：物理地址，也就是消息在日志分段文件中对应的物理位置，占4个字节</li></ul><p>消息的偏移量占8个字节，也就是绝对偏移量。索引项中没有直接使用绝对偏移量，而用相对偏移量，就减少索引文件占用的文件。</p><h2 id="时间戳索引"><a href="#时间戳索引" class="headerlink" title="时间戳索引"></a>时间戳索引</h2><p>时间戳索引项的格式</p><p><img src="/2022/09/13/Kafka%E6%97%A5%E5%BF%97%E5%AD%98%E5%82%A8/shijianchuo.png"></p><ul><li>timestamp：当前日志分段最大的时间戳</li><li>relativeOffset：时间戳所对应的消息的相对偏移量</li></ul><p>时间戳索引文件中包含若干时间戳索引项，每个追加的时间戳索引项中的timestamp必大于之前追加的索引项的timestamp，不然不追加。若broker端log.message.timestamp.type设置为LogAppendTime，那消息的时间戳必定能保持单调递增；反之，若是CreateTime类型就不能保证。生产者可以使用类似ProducerRecord的方法来指定时间戳的值。即使生产者客户端采用自动插入的时间戳也无法保证时间戳能单调递增，若两个不同时钟的生产者同时向一个分区插消息，也会造成当前分区的时间戳乱序。</p><p>与偏移量索引文件相似，时间戳索引文件大小必须是索引项大小的整数倍，不满足的会进行裁剪。</p><h1 id="日志清理"><a href="#日志清理" class="headerlink" title="日志清理"></a>日志清理</h1><p>Kafka将消息存储在磁盘，为了控制磁盘占用空间的不断增加就需要对消息做一定的清理操作。Kafka中每个分区副本都对应一个Log，而Log可以分为多个日志分段，这样便于日志的清理操作。</p><p>清理策略：</p><ul><li>日志删除：按照一定的保留策略直接删除不符合条件的日志分段。</li><li>日志压缩：针对每个消息的key进行整合，对于有相同key的不同value，只保留最后一个版本</li></ul><p>通过broker端参数log.cleanup.policy来设置日志清理策略，默认是‘delete’，即采用日志删除的清理策略。</p><p>日志清理的粒度可以控制到主题级别。</p><h2 id="日志删除"><a href="#日志删除" class="headerlink" title="日志删除"></a>日志删除</h2><p>在Kafka的日志管理器中会有一个专门的日志删除任务来周期性地检测和删除不符合保留条件的日志分段文件。默认是5分钟（broker端参数log.retention.check.interval.ms来配置）。</p><p>日志分段有三种保留策略。</p><ul><li>基于时间的保留策略：日志删除任务会检查当前日志文件中是否有保留时间超过设定的阈值来找删除的日志分段集合。</li></ul><p>​查找过期的日志分段文件是根据日志分段中最大的时间戳largestTimeStamp来计算的，因为该值可以被修改，所以不能反映日志分段在磁盘保留的时间。</p><p>​<em>若待删除的日志分段的总数比该日志文件中的所有的日志分段的数量大，那就是所有日志分段都过期了，但文件还要有一个日志分段用来接收消息的写入，该情况下会先切分出一个新的日志分段作为活跃的日志分段，然后再删除</em>。</p><p>​删除日志分段：先会从Log对象中所维护日志分段的跳跃表中移除待删除的日志分段，以保证没有线程对该分段读取；再将日志分段所对应的所有文件添加”.delete”的后缀；最后交由一个以”delete-file”命名的延迟任务去删除这些文件，延时时间默认为1分钟。</p><ul><li>基于日志大小保留策略：检查当前日志大小是否超过了设定的阈值来寻找可删除的日志分段的文件集合。阈值可通过broker参数log.retention.bytes配置<em><strong>所有日志文件的总大小</strong></em>，默认是-1表示无穷大；<em><strong>单个日志分段大小</strong></em>由broker端参数log.segment.bytes来限制，默认1GB。</li></ul><p>​删除日志分段：计算日志文件的总大小和总阈值的差值，即计算需要删除的日志总大小，再从日志文件中的第一个日志分段开始进行查找可删除的日志分段集合，找到后就删除。剩下的与时间保留策略的删除相同。</p><ul><li>基于日志起始偏移量的保留策略：某日志分段的下一个日志分段的起始的偏移量是否小于等于logStartOffset，若是则可以删除。</li></ul><p>​收集日志并删除：从头开始遍历每个日志分段，偏移量也随着增加，直到阈值。删除与上面基本相同</p><h2 id="日志压缩"><a href="#日志压缩" class="headerlink" title="日志压缩"></a>日志压缩</h2><p>对于有相同key的不同value值，只保留最后一个版本。若只关心key对应的最新value值，则可以开启日志清理，Kafka会定期将相同key的消息合并，只保留最新的value值。</p><p>类比于Redis的RDB的持久化模式。若是日志删除，在系统异常崩溃后就要读取Kafka所有数据进行恢复；若是日志压缩，就可以<strong>减少数据的加载量而加快系统恢复速度</strong>*。日志压缩在某些情景下可以简化技术栈，提高系统整体质量。</p><p>删除key时：Kafka提供了<em><strong>墓碑消息</strong></em>，一条消息的key不为null，但是value为null。日志清理线程发现墓碑消息时会先进行常规的清理，并保留墓碑消息一段时间。</p><p>日志压缩执行后日志分段的大小会更小，为了防止出现太多小文件，所以在实际清理过程中不对单个日志分段进行单独清理，而是将偏移量从0到firstUncleannableOffset的所有日志分段分组，每个日志分段只属于一组。</p><h1 id="磁盘存储"><a href="#磁盘存储" class="headerlink" title="磁盘存储"></a>磁盘存储</h1><p>Kafka依赖于文件系统（更底层地说是磁盘）存储和缓存消息。在传统的RabbitMQ就使用内存默认为存储介质，磁盘为备选以实现高吞吐和低延迟。</p><p>Kafka用文件追加的方式写入消息，且不允许修改已写入的消息。</p><h2 id="页缓存"><a href="#页缓存" class="headerlink" title="页缓存"></a>页缓存</h2><p>页缓存是操作系统实现的一种主要的磁盘缓存，以较少磁盘I&#x2F;O操作。把磁盘的数据缓存到内存中，把对磁盘的访问变为对内存的访问。</p><p>当进程准备读取磁盘上的文件内容时，操作系统会先查看读取的数据所在的页是否在页缓存中，命中就返回数据，就避免磁盘I&#x2F;O操作；没命中，磁盘就向磁盘发起读取请求并将读取的数据也存入页缓存，之后再返回给进程。写数据时，也看是否命中，没命中就添加相应的页，将数据写入该页，操作系统再定时把脏页写入磁盘。</p><p><em><strong>Kafka使用了大量页缓存，即实现高吞吐的重要因素之一</strong></em>。消息先写入缓存，再操作系统负载刷盘任务，Kafka中也提供了同步刷盘（可提高消息的可靠性，但页缓存可能因机器异常而消息丢失）及间断性强制刷盘功能。刷盘最好就让操作系统负载，消息可靠性应该由多副本机制保证。</p><p>Linux会使用磁盘的一部分作文swap分区，可以进行进程调度：把当前不活跃的进程调入该分区，内存空出来的给活跃的进程用。对Kafka应该避免该内存的交换，因为其使用了大量系统页缓存，该方法性能影响很大</p><h2 id="零拷贝"><a href="#零拷贝" class="headerlink" title="零拷贝"></a>零拷贝</h2><p>将数据直接从磁盘文件复制到网卡设备中，不用经过应用程序。提高了程序的性能，减少了内核和用户模式之间的上下切换。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h1&gt;&lt;p&gt;若分区规则合理，那么所有的消息可以均匀的分布到不同的分区中，可以实现水平拓展。不考虑多副本的情况，一个分区对应一个日志。为防止log太大，所</summary>
      
    
    
    
    <category term="消息队列" scheme="http://example.com/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
    <category term="Kafka" scheme="http://example.com/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>Kafka主题和分区</title>
    <link href="http://example.com/2022/09/07/Kafka%E4%B8%BB%E9%A2%98%E5%92%8C%E5%88%86%E5%8C%BA/"/>
    <id>http://example.com/2022/09/07/Kafka%E4%B8%BB%E9%A2%98%E5%92%8C%E5%88%86%E5%8C%BA/</id>
    <published>2022-09-07T15:35:31.000Z</published>
    <updated>2022-09-07T15:38:08.520Z</updated>
    
    <content type="html"><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>主题作为消息的归类，可以再细分为一个或多个分区，分区可以看做对消息的第二次归类。分区提高了Kafka可伸缩性、水平拓展的功能。</p><p>从Kafka底层实现看，主题和分区都是逻辑概念，分区可以有一至多个副本，每个副本对应一个日志文件，每个日志文件对应一至多个日志分段，每个日志分段还可以细分为索引文件、日志存储文件和快照文件。</p><h1 id="主题的管理"><a href="#主题的管理" class="headerlink" title="主题的管理"></a>主题的管理</h1><p>主题、分区、副本和Log的关系。主题和分区是提供给上层用户的抽象，副本层面或Log层面才是实际物理上的存在。同一个分区中的多个副本必须分布在不同的broker中，才能提供有效的数据冗余</p><p><img src="/2022/09/07/Kafka%E4%B8%BB%E9%A2%98%E5%92%8C%E5%88%86%E5%8C%BA/guanxi.png"></p><ul><li>创建主题：broker端配置了auto.create.topics.enable参数为true时，当生产者向一个尚未创建的主题发送消息时，会自动创建一个分区数位num.partitiions，副本因子为default.replication.factor的主题。当一个消费者开始从未知主题读取消息时或任意一个客户端向未知主题发送元数据都会根据这两个参数创建一对对应的主题。但因为行为非预期，不建议使用。</li><li>分区副本的分配：生产者的分区分配是每条消息指定其所要发往的分区，消费者的分区分配是值为消费者指定其可以消费信息的分区。此处的分区分配指为集群指定创建主题时分区副本分配方案，即在哪个broker中创建哪些分区的副本</li><li>修改主题：当一个主题被创建后，可能需要修改分区个数、修改配置等</li></ul><h1 id="分区的管理"><a href="#分区的管理" class="headerlink" title="分区的管理"></a>分区的管理</h1><p>分区使用多副本机制提升可靠性，但<em><strong>只有leader副本对外提供读写服务</strong></em>，而follower副本只负责在<em><strong>内部进行消息的同步</strong></em>。若一个分区的leader副本不可用，那么整个分区就不可用，此时Kafka会从follower副本选举一个新的leader副本来对外服务。创建主题的时候，该主题的分区及副本会尽可能均匀分布在各个broker节点上，对应的leader副本的分配也较均匀</p><p>为了治理负载失衡的情况，Kafka引入了优先副本的概念。优先副本是指在AR集合列表中的第一个副本，理想情况，优先副本就是该分区的leader副本。Kafka要确保所有主题的优先副本在Kafka集群中均匀分布，这样就保证了所有分区的leader均衡分布，若leader分布过于集中就会集群负载不均衡。</p><p>分区重分配：当集群中的一个节点宕机下线，若节点上的分区是单副本，那该分区就变得不可用，在恢复前，相应的数据是丢失的；若节点上的分区是多副本，那么位于该节点上的leader副本会转交到集群其他follower副本中。总之，该节点上的分区副本已功能失效，Kafka不会将这些失效的分区副本自动迁移到集群中升序的可用broker节点上，但不管会影响集群的均衡负载。当要对集群的一个节点下线时，需要将该节点上的分区副本迁移到其他可用节点上。本质：数据复制，先增加新副本，再数据同步，最后删除旧副本</p><p>复制限流：分区重分配过程中，数据复制会占用额外资源，若重分配的量太大会影响性能。所以，减少重分配粒度，以小批次的方式操作。若某个主题或某个分区的流量在某段时间过大，只靠减小粒度还是不行，这时就需要一个限流的机制</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h1&gt;&lt;p&gt;主题作为消息的归类，可以再细分为一个或多个分区，分区可以看做对消息的第二次归类。分区提高了Kafka可伸缩性、水平拓展的功能。&lt;/p&gt;
&lt;p</summary>
      
    
    
    
    <category term="消息队列" scheme="http://example.com/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
    <category term="Kafka" scheme="http://example.com/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>Kafka消费者</title>
    <link href="http://example.com/2022/09/06/Kafka%E6%B6%88%E8%B4%B9%E8%80%85/"/>
    <id>http://example.com/2022/09/06/Kafka%E6%B6%88%E8%B4%B9%E8%80%85/</id>
    <published>2022-09-05T17:13:17.000Z</published>
    <updated>2022-09-05T17:16:27.603Z</updated>
    
    <content type="html"><![CDATA[<h1 id="简述"><a href="#简述" class="headerlink" title="简述"></a>简述</h1><p>消费者<em><strong>负责订阅Kafka中的主题，并且从订阅的主题上拉取消息</strong></em>，与其他消息中间件不同的是，kafka的消费理念中有一层消费组的概念。<em><strong>每一个分区只能被同一个消费组中的一个消费者消费</strong></em></p><p>消费者和消费者组的模型可以让整体的消费能力具备横向伸缩性，可以改变消费者的个数而改变消费能力，过多或过少都不能改变能力。</p><p>消费组是一个<em><strong>逻辑上的概念</strong></em>，将里面的消费者归于一类，每个消费者只属于一个消费组（有固定名称），消费者在消费前需要指定所属组的名称；消费者是<em><strong>实际的应用实例</strong></em>，可以是一个线程或进程，同一个消费组内的消费者可部署在同一机器或不同机器</p><p>对于消息中间件一般由两种消息投递模式：</p><ul><li>点对点模式：基于队列，消息生产者发送消息到队列，消息消费者从队列中接收消息。</li><li>发布&#x2F;订阅模式：定义了如何向一个内容节点（主题）发布和订阅消息。主题相当于消息传递的中介。消息发布者将消息发布到某个主题，而消息订阅者从主题中订阅消息，主题使得两者互相保持独立，不需要进行接触就可以保证消息的传递，发布&#x2F;订阅模式在消息的一对多广播时采用。</li></ul><p>而Kafka同时支持以上两种消息投递模式：若所有消费者在同一个组，那么所有消息都会被均衡地投递给每一个消费者，即每条消息只会被一个消费者处理，就相当于点对点；若所有消费者在不同消费者，那么所有消息都会被广播给所有消费者，即每条消息都会被所有消费者处理，就相当于发布&#x2F;订阅模式的应用</p><p>正常的消费逻辑：订阅消费者客户端参数以及创建相应的消费者实例；订阅主题；拉取消息并消费；提交消费位移；关闭消费者实例</p><p>Kafka中的消费<em><strong>基于拉模式</strong></em>。消息的消费模式一般由两种模式：推模式（服务端主动将消息推送给消费者）和拉模式（消费者主动向服务端发起请求来拉取消息）。Kafka中的消息消费是一个不断轮询的过程，消费者就重复调用poll()方法，获取的就是所订阅的主题（分区）上的一组消息。</p><p>对于Kafka的分区，每条消息都有唯一的offset，消费偏移量，表示消息在分区中对应的位置。而消费者使用offset表示消费到分区中某个消息所在的位置，位移。在每次调用poll()方法，返回的是还没有被消费过的消息集，所以需要记录上一次消费时的消费位移，且该消费位移需要持久化保持（不能是保存在内存，不然重启后消费者就不知道位移了；若新的消费者加入，就会有均衡动作，对于同一分区，会可能在均衡后分配给新的消费者）</p><p><img src="/2022/09/06/Kafka%E6%B6%88%E8%B4%B9%E8%80%85/next.png"></p><p>X就是某一次拉取操作中此分区消息的最大偏移量。所以当前消费者需要提交的消费位移就是X+1</p><p>消费者中也有控制消费速度的方法。pause()和resume()分别实现暂停某些分区在拉取操作时返回数据给客户端和恢复某些分区向客户端返回数据的操作</p><p>再均衡：分区的所属权从一个消费者转移到另一消费者的行为，它为消费者具备高可用性和伸缩性提供保障，我们能安全方便的删除或添加消费组内的消费者。但是在均衡发生时间内，消费组不可用；一个分区被重新分配给另一个消费者时，消费者当前状态也会丢失。</p><p>消费者拦截器<em><strong>主要在消费到消息或在提交消费位移时进行定制化的操作</strong></em></p><p>KafkaConsumer&#x3D;&#x3D;非线程安全&#x3D;&#x3D;。里有acquire()方法检测当前是否只有一个线程在操作，若有多个线程就抛异常，与锁不同，因为它不会造成阻塞等待，仅仅通过&#x3D;&#x3D;线程操作计算标记的方式来检测线程是否发生了并发操作&#x3D;&#x3D;。KafkaConsumer中的每个公用方法执行前都会调用该方法（除了wakeup()方法）。</p><p>KafkaConsumer的非线程安全不是意味着消费消息只能单线程方式执行。若生产者发送消息的速度比消费者的速度更快，就会有越来越多消息来不及消费而造成延迟。Kafka中消息由保留作用，有些消息可能在被消费前就被清理了，从而消息丢失。使用多线程消息消费可以提高整体消费能力。</p><p>多线程实现方式：</p><ul><li>线程封闭：即每个线程实例化一个KafkaConsumer对象，一个线程对应一个KafkaConsumer实例，消费线程。一个消费线程可以消费一个或多个分区中的消息，所有消费线程属于同一个消费组。该方法的并发度受限于分区的实际个数，消费线程更多，会有部分空闲</li><li>多个消费线程消费同一个分区，可提高消费能力，但位移提交和顺序控制的处理会很复杂，使用的极少。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;简述&quot;&gt;&lt;a href=&quot;#简述&quot; class=&quot;headerlink&quot; title=&quot;简述&quot;&gt;&lt;/a&gt;简述&lt;/h1&gt;&lt;p&gt;消费者&lt;em&gt;&lt;strong&gt;负责订阅Kafka中的主题，并且从订阅的主题上拉取消息&lt;/strong&gt;&lt;/em&gt;，与其他消息中间件不同的是，</summary>
      
    
    
    
    <category term="消息队列" scheme="http://example.com/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
    <category term="Kafka" scheme="http://example.com/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>Kafka生产者</title>
    <link href="http://example.com/2022/09/04/Kafka%E7%94%9F%E4%BA%A7%E8%80%85/"/>
    <id>http://example.com/2022/09/04/Kafka%E7%94%9F%E4%BA%A7%E8%80%85/</id>
    <published>2022-09-03T16:15:57.000Z</published>
    <updated>2022-09-03T16:21:39.149Z</updated>
    
    <content type="html"><![CDATA[<h1 id="生产者"><a href="#生产者" class="headerlink" title="生产者"></a>生产者</h1><p>消息生产者，把消息投递到Kafka中</p><p>当创建真正的生产者实例前需要配置相应的参数。比如连接的Kafka集群地址。</p><p>&#x3D;&#x3D;producer线程安全&#x3D;&#x3D;，可以在多个线程中共享单个producer实例，也可以将实例进行池化来供其他线程调用</p><p>发送消息的三种模式：发后即忘（发送消息不管是否到达，在某些时候会造成消息丢失，性能最高可靠性最差）、同步、异步。</p><p>两种异常：可重试异常和不可重试的异常</p><p>生产者需要用序列化器把对象转成字节数组才能通过网络发给Kafka。相对的，消费者需要反序列化器把字节数组转换成相应的对象。两者需要一一对应。</p><p>消息通过send方法发往broker的过程，可能要拦截器（非必须）、序列化器（必须）、分区器的系列作用之后才能发往broker。若没有指定partition字段，就需要依赖分区器，根据key计算partition的值。</p><p>生产者拦截器：在消息发送前做一些准备工作，比如按某个规则过滤消息等等。producer在序列化和计算分区之前调用拦截器的onsend()方法对消息进行定制化操作</p><h1 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h1><h2 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h2><p>生产者客户端整体架构</p><p><img src="/2022/09/04/Kafka%E7%94%9F%E4%BA%A7%E8%80%85/liucheng.png"></p><p>整个生产者客户端由两个线程协调运行（主线程和sender线程）。发送线程负责从RecordAccumulator中获取消息并将其发送到Kafka中。</p><p><em><strong>RecordAccumulator主要是用来缓存消息，让sender线程可以批量发送，以减少网络传输的资源消耗以提升性能</strong></em>。（默认32MB）。若生产者发送消息的速度超过发送到服务器的速度，生产者空间就会不足，此时的send()方法会被阻塞或抛异常。内部为每个分区都维护一个双端队列（producerBatch，一个消息批次）；消息在网络上是以字节的形式传输，发送前要创建一块内存区域来保存对应的消息，内部还有一个BufferPool，以实现ByteBuffer的复用，实现缓存高效利用。</p><p>主线程发送的消息会追加到RecordAccumulator的某个双端队列中，sender读取消息时从队列的头部读取消息，从缓存中获取消息，会改变原本的保存形式&lt;Node,List<ProducerBatch>&gt;，node就是Kafka集群中的broker节点。对于网络连接，生产者客户端是与具体的broker节点建立连接和发送消息，而不关心消息属于哪个分区；而producer的应用逻辑而言，只关注向哪个分区中发送哪些消息。</ProducerBatch></p><p>&lt;Node,List<ProducerBatch>&gt;还会封装成&lt;Node,Request&gt;，就可以将request请求发往各个node。Request是Kafka的各种协议请求。</ProducerBatch></p><p>请求从sender发往Kafka之前还会保存在InFlightRequests中。InFlightRequests中对象形式是Map&lt;NodeId,Deque<Request>&gt;就是<em><strong>缓存了已经发出去但没有收到响应的请求</strong></em>（NodeId是节点的id编号，String类型）；还提供了管理类的方法，可通过参数限制每个连接最多缓存的请求数</Request></p><h2 id="元数据更新"><a href="#元数据更新" class="headerlink" title="元数据更新"></a>元数据更新</h2><p>InFlightRequests可以获得leastLoadedNode，即所有Node节点中负载最小的（比如上图的node2）。选择该节点可以让它尽快发出，避免因网络阻塞等异常而影响整体的进度。</p><p>producer需要将消息追加到指定主题的某个分区所对应的leader副本之前，要知道主题的分区数量，再计算出目标分区，之后producer需要leader副本所在broker节点的地址、端口等信息才能建立连接，最终才能发送到Kafka。该过程中所需要的信息都是元数据信息。</p><p>元数据指Kafka集群的元数据，记录了集群中有哪些主题，主题有哪些分区，每个分区的leader副本、follow副本分配在哪个节点上，哪些副本在AR、ISR等集合中，集群中有哪些节点，控制器节点又是哪一个等信息。元数据的更新操作是在客户端内部进行，对客户端的外部使用者不可见。需要更新时，先选leastLoadedNode，再向该Node发送请求获取具体的元数据信息（sender线程发起），请求同样会存入InFightRequests。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;生产者&quot;&gt;&lt;a href=&quot;#生产者&quot; class=&quot;headerlink&quot; title=&quot;生产者&quot;&gt;&lt;/a&gt;生产者&lt;/h1&gt;&lt;p&gt;消息生产者，把消息投递到Kafka中&lt;/p&gt;
&lt;p&gt;当创建真正的生产者实例前需要配置相应的参数。比如连接的Kafka集群地址。&lt;/p</summary>
      
    
    
    
    <category term="消息队列" scheme="http://example.com/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
    <category term="Kafka" scheme="http://example.com/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>as-if-serial和happens-before</title>
    <link href="http://example.com/2022/08/31/as-if-serial%E5%92%8Chappens-before/"/>
    <id>http://example.com/2022/08/31/as-if-serial%E5%92%8Chappens-before/</id>
    <published>2022-08-31T15:48:18.000Z</published>
    <updated>2022-08-31T15:52:04.646Z</updated>
    
    <content type="html"><![CDATA[<p>我们知道为了提高并行度，优化程序性能，编译器和处理器会对代码进行指令重排序。但为了不改变程序的执行结果，尽可能地提高程序执行的并行度，我们需要了解as-if-serial规则和happens-before规则。</p><h3 id="as-if-serial规则"><a href="#as-if-serial规则" class="headerlink" title="as-if-serial规则"></a>as-if-serial规则</h3><p>as-if-serial语义的意思指：<strong>不管怎么重排序（编译器和处理器为了提高并行度），（单线程）程序的执行结果不能被改变。</strong> 编译器、runtime和处理器都必须遵守as-if-serial语义。<br>为了遵守as-if-serial语义，<strong>编译器和处理器不会对存在数据依赖关系的操作做重排序，因为这种重排序会改变执行结果。</strong> 但是，如果操作之间不存在数据依赖关系，这些操作可能被编译器和处理器重排序。示例代码如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">COPYint a=<span class="number">1</span>;</span><br><span class="line"><span class="type">int</span> b=<span class="number">2</span>;</span><br><span class="line"><span class="type">int</span> c=a+b;</span><br></pre></td></tr></table></figure><p>a和c之间存在数据依赖关系，同时b和c之间也存在数据依赖关系。因此在最终执行的指令序列中，c不能被重排序到A和B的前面（c排到a和b的前面，程序的结果将会被改变）。但a和b之间没有数据依赖关系，编译器和处理器可以重排序a和b之间的执行顺序。</p><h3 id="happens-before（先行发生）规则"><a href="#happens-before（先行发生）规则" class="headerlink" title="happens-before（先行发生）规则"></a>happens-before（先行发生）规则</h3><h4 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h4><p>JMM可以通过happens-before关系向程序员提供跨线程的内存可见性保证（如果A线程的写操作a与B线程的读操作b之间存在happens-before关系，尽管a操作和b操作在不同的线程中执行，但JMM向程序员保证a操作将对b操作可见）。具体的定义为：</p><ol><li><strong>如果一个操作happens-before另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前。</strong></li><li>两个操作之间存在happens-before关系，并不意味着Java平台的具体实现必须要按照happens-before关系指定的顺序来执行。<strong>如果重排序之后的执行结果，与按happens-before关系来执行的结果一致，那么JMM允许这种重排序。</strong></li></ol><h4 id="八大规则"><a href="#八大规则" class="headerlink" title="八大规则"></a>八大规则</h4><table><thead><tr><th>规则</th><th>解释</th></tr></thead><tbody><tr><td>程序次序规则</td><td>在一个线程内，代码按照书写的控制流顺序执行</td></tr><tr><td>管程锁定规则</td><td>一个 unlock 操作先行发生于后面对同一个锁的 lock 操作</td></tr><tr><td>volatile 变量规则</td><td>volatile 变量的写操作先行发生于后面对这个变量的读操作</td></tr><tr><td>线程启动规则</td><td>Thread 对象的 start() 方法先行发生于此线程的每一个动作</td></tr><tr><td>线程终止规则</td><td>线程中所有的操作都先行发生于对此线程的终止检测(通过 Thread.join() 方法结束、 Thread.isAlive() 的返回值检测)</td></tr><tr><td>线程中断规则</td><td>对线程 interrupt() 方法调用优先发生于被中断线程的代码检测到中断事件的发生 (通过 Thread.interrupted() 方法检测)</td></tr><tr><td>对象终结规则</td><td>一个对象的初始化完成(构造函数执行结束)先行发生于它的 finalize() 方法的开始</td></tr><tr><td>传递性</td><td>如果操作 A 先于 操作 B 发生，操作 B 先于 操作 C 发生，那么操作 A 先于 操作 C</td></tr></tbody></table><h3 id="as-if-serial规则和happens-before规则的区别"><a href="#as-if-serial规则和happens-before规则的区别" class="headerlink" title="as-if-serial规则和happens-before规则的区别"></a>as-if-serial规则和happens-before规则的区别</h3><ol><li>as-if-serial语义保证单线程内程序的执行结果不被改变，happens-before关系保证<strong>正确同步的多线程</strong>程序的执行结果不被改变。</li><li>as-if-serial语义给编写单线程程序的程序员创造了一个幻觉：单线程程序是按程序的顺序来执行的。happens-before关系给编写正确同步的多线程程序的程序员创造了一个幻觉：正确同步的多线程程序是按happens-before指定的顺序来执行的。</li><li>as-if-serial语义和happens-before这么做的目的，都是为了在不改变程序执行结果的前提下，尽可能地提高程序执行的并行度。</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;我们知道为了提高并行度，优化程序性能，编译器和处理器会对代码进行指令重排序。但为了不改变程序的执行结果，尽可能地提高程序执行的并行度，我们需要了解as-if-serial规则和happens-before规则。&lt;/p&gt;
&lt;h3 id=&quot;as-if-serial规则&quot;&gt;&lt;a </summary>
      
    
    
    
    <category term="基础" scheme="http://example.com/categories/%E5%9F%BA%E7%A1%80/"/>
    
    
    <category term="基础" scheme="http://example.com/tags/%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>Eureka部分源码</title>
    <link href="http://example.com/2022/08/27/Eureka%E9%83%A8%E5%88%86%E6%BA%90%E7%A0%81/"/>
    <id>http://example.com/2022/08/27/Eureka%E9%83%A8%E5%88%86%E6%BA%90%E7%A0%81/</id>
    <published>2022-08-27T13:35:29.000Z</published>
    <updated>2022-08-27T13:42:55.496Z</updated>
    
    <content type="html"><![CDATA[<h1 id="简述"><a href="#简述" class="headerlink" title="简述"></a>简述</h1><p>底层通过Jersey框架在AWS背景下实现，用过滤器做服务的拦截。核心就是把<em><strong>过滤器注册进Tomcat</strong></em></p><p>多个模块都会向eureka发送服务注册的请求（会有注册信息），eureka底层会有一个注册表，当各个模块间进行通信的时候会定期拉取注册表的信息。模块要向另一个模块通信的时候会看是否有注册信息，有就通过信息得到对应的地址，就可以访问。</p><p>会维护心跳连接&#x2F;服务下架&#x2F;服务剔除&#x2F;服务续约。自我保护机制、集群通讯。</p><p>模块包括：定期拉取注册表信息、全量拉取、增量拉取 </p><h1 id="部分源码"><a href="#部分源码" class="headerlink" title="部分源码"></a>部分源码</h1><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//在启动类点击@EnableEurekaServer注解</span></span><br><span class="line"><span class="meta">@Target(&#123;ElementType.TYPE&#125;)</span></span><br><span class="line"><span class="meta">@Retention(RetentionPolicy.RUNTIME)</span></span><br><span class="line"><span class="meta">@Documented</span></span><br><span class="line"><span class="meta">@Import(&#123;EurekaServerMarkerConfiguration.class&#125;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="meta">@interface</span> EnableEurekaServer &#123;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//由Import注解可知，使用了动态代理</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@Configuration(</span></span><br><span class="line"><span class="meta">    proxyBeanMethods = false</span></span><br><span class="line"><span class="meta">)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">EurekaServerMarkerConfiguration</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">EurekaServerMarkerConfiguration</span><span class="params">()</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> EurekaServerMarkerConfiguration.Marker <span class="title function_">eurekaServerMarkerBean</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">EurekaServerMarkerConfiguration</span>.Marker();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">class</span> <span class="title class_">Marker</span> &#123;</span><br><span class="line">        Marker() &#123;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//虽然逻辑是空的，但是由于自动装配，它会往容器里面装配开发人员所写的配置文件的内容。作用在后面</span></span><br></pre></td></tr></table></figure><p><img src="/2022/08/27/Eureka%E9%83%A8%E5%88%86%E6%BA%90%E7%A0%81/factories.png"></p><p>Spring.factories</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">org.springframework.boot.autoconfigure.EnableAutoConfiguration=\</span><br><span class="line">  org.springframework.cloud.netflix.eureka.server.EurekaServerAutoConfiguration<span class="comment">//该类才是eureka核心</span></span><br></pre></td></tr></table></figure><h2 id="EurekaServerAutoConfiguration"><a href="#EurekaServerAutoConfiguration" class="headerlink" title="EurekaServerAutoConfiguration"></a>EurekaServerAutoConfiguration</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//声明配置类</span></span><br><span class="line"><span class="meta">@Configuration(</span></span><br><span class="line"><span class="meta">    proxyBeanMethods = false</span></span><br><span class="line"><span class="meta">)</span></span><br><span class="line"><span class="comment">//动态注入bean到容器</span></span><br><span class="line"><span class="meta">@Import(&#123;EurekaServerInitializerConfiguration.class&#125;)</span></span><br><span class="line"><span class="comment">//条件注入，判断当前Spring容器是否会有Marker的bean。</span></span><br><span class="line"><span class="meta">@ConditionalOnBean(&#123;Marker.class&#125;)</span></span><br><span class="line"><span class="comment">//所以，到目前为止，当在启动类中加入EnableEurekaServer注解后，会将Marker注入到Spring容器里面，然后在配置eureka时，发现了有Marker就会把EurekaServerAutoConfiguration注入</span></span><br><span class="line"><span class="comment">//相应的配置文件</span></span><br><span class="line"><span class="meta">@EnableConfigurationProperties(&#123;EurekaDashboardProperties.class, InstanceRegistryProperties.class&#125;)</span></span><br><span class="line"><span class="meta">@PropertySource(&#123;&quot;classpath:/eureka/server.properties&quot;&#125;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">EurekaServerAutoConfiguration</span> <span class="keyword">implements</span> <span class="title class_">WebMvcConfigurer</span> &#123;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">EurekaServerAutoConfiguration</span> <span class="keyword">implements</span> <span class="title class_">WebMvcConfigurer</span> &#123;</span><br><span class="line">......</span><br><span class="line">     <span class="comment">//核心，把过滤器注册进Tomcat</span></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> FilterRegistrationBean&lt;?&gt; jerseyFilterRegistration(Application eurekaJerseyApp) &#123;</span><br><span class="line">        FilterRegistrationBean&lt;Filter&gt; bean = <span class="keyword">new</span> <span class="title class_">FilterRegistrationBean</span>();</span><br><span class="line">        bean.setFilter(<span class="keyword">new</span> <span class="title class_">ServletContainer</span>(eurekaJerseyApp));</span><br><span class="line">        bean.setOrder(<span class="number">2147483647</span>);</span><br><span class="line">        bean.setUrlPatterns(Collections.singletonList(<span class="string">&quot;/eureka/*&quot;</span>));</span><br><span class="line">        <span class="keyword">return</span> bean;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//所定义的过滤器</span></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> Application <span class="title function_">jerseyApplication</span><span class="params">(Environment environment, ResourceLoader resourceLoader)</span> &#123;</span><br><span class="line">        <span class="type">ClassPathScanningCandidateComponentProvider</span> <span class="variable">provider</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ClassPathScanningCandidateComponentProvider</span>(<span class="literal">false</span>, environment);</span><br><span class="line">        provider.addIncludeFilter(<span class="keyword">new</span> <span class="title class_">AnnotationTypeFilter</span>(Path.class));</span><br><span class="line">        provider.addIncludeFilter(<span class="keyword">new</span> <span class="title class_">AnnotationTypeFilter</span>(Provider.class));</span><br><span class="line">        Set&lt;Class&lt;?&gt;&gt; classes = <span class="keyword">new</span> <span class="title class_">HashSet</span>();</span><br><span class="line">        String[] var5 = EUREKA_PACKAGES;</span><br><span class="line">        <span class="type">int</span> <span class="variable">var6</span> <span class="operator">=</span> var5.length;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> <span class="variable">var7</span> <span class="operator">=</span> <span class="number">0</span>; var7 &lt; var6; ++var7) &#123;</span><br><span class="line">            <span class="type">String</span> <span class="variable">basePackage</span> <span class="operator">=</span> var5[var7];</span><br><span class="line">            Set&lt;BeanDefinition&gt; beans = provider.findCandidateComponents(basePackage);</span><br><span class="line">            <span class="type">Iterator</span> <span class="variable">var10</span> <span class="operator">=</span> beans.iterator();</span><br><span class="line"></span><br><span class="line">            <span class="keyword">while</span>(var10.hasNext()) &#123;</span><br><span class="line">                <span class="type">BeanDefinition</span> <span class="variable">bd</span> <span class="operator">=</span> (BeanDefinition)var10.next();</span><br><span class="line">                Class&lt;?&gt; cls = ClassUtils.resolveClassName(bd.getBeanClassName(), resourceLoader.getClassLoader());</span><br><span class="line">                classes.add(cls);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        Map&lt;String, Object&gt; propsAndFeatures = <span class="keyword">new</span> <span class="title class_">HashMap</span>();</span><br><span class="line">        propsAndFeatures.put(<span class="string">&quot;com.sun.jersey.config.property.WebPageContentRegex&quot;</span>, <span class="string">&quot;/eureka/(fonts|images|css|js)/.*&quot;</span>);</span><br><span class="line">        <span class="type">DefaultResourceConfig</span> <span class="variable">rc</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DefaultResourceConfig</span>(classes);</span><br><span class="line">        rc.setPropertiesAndFeatures(propsAndFeatures);</span><br><span class="line">        <span class="keyword">return</span> rc;</span><br><span class="line">    &#125;</span><br><span class="line">    ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//客户端启动时会发送服务注册的请求就会进入该方法。</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ApplicationResource</span> &#123;</span><br><span class="line"><span class="meta">@POST</span></span><br><span class="line">    <span class="meta">@Consumes(&#123;&quot;application/json&quot;, &quot;application/xml&quot;&#125;)</span></span><br><span class="line">    <span class="comment">//info里面就是相关的注册信息</span></span><br><span class="line">    <span class="keyword">public</span> Response <span class="title function_">addInstance</span><span class="params">(InstanceInfo info, <span class="meta">@HeaderParam(&quot;x-netflix-discovery-replication&quot;)</span> String isReplication)</span> &#123;</span><br><span class="line">        logger.debug(<span class="string">&quot;Registering instance &#123;&#125; (replication=&#123;&#125;)&quot;</span>, info.getId(), isReplication);</span><br><span class="line">        <span class="comment">//必要的信息一定不能为空</span></span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">this</span>.isBlank(info.getId())) &#123;</span><br><span class="line">            <span class="keyword">return</span> Response.status(<span class="number">400</span>).entity(<span class="string">&quot;Missing instanceId&quot;</span>).build();</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="built_in">this</span>.isBlank(info.getHostName())) &#123;</span><br><span class="line">            <span class="keyword">return</span> Response.status(<span class="number">400</span>).entity(<span class="string">&quot;Missing hostname&quot;</span>).build();</span><br><span class="line">        &#125; </span><br><span class="line">        ......</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">//其他信息的处理</span></span><br><span class="line">           ......</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="built_in">this</span>.registry.register(info, <span class="string">&quot;true&quot;</span>.equals(isReplication));</span><br><span class="line">            <span class="keyword">return</span> Response.status(<span class="number">204</span>).build();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//发布监听</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">InstanceRegistry</span> <span class="keyword">extends</span> <span class="title class_">PeerAwareInstanceRegistryImpl</span> <span class="keyword">implements</span> <span class="title class_">ApplicationContextAware</span> &#123;</span><br><span class="line">    ......</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">register</span><span class="params">(<span class="keyword">final</span> InstanceInfo info, <span class="keyword">final</span> <span class="type">boolean</span> isReplication)</span> &#123;</span><br><span class="line">         <span class="comment">//监听事件。（自己指定事件，在类上添加@Compoent，在方法上@EventListener，方法参数就是事件类型）</span></span><br><span class="line">        <span class="built_in">this</span>.handleRegistration(info, <span class="built_in">this</span>.resolveInstanceLeaseDuration(info), isReplication);</span><br><span class="line">        <span class="built_in">super</span>.register(info, isReplication);</span><br><span class="line">    &#125;</span><br><span class="line">    ......</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//集群间的信息共享</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">PeerAwareInstanceRegistryImpl</span> <span class="keyword">extends</span> <span class="title class_">AbstractInstanceRegistry</span> <span class="keyword">implements</span> <span class="title class_">PeerAwareInstanceRegistry</span> &#123;</span><br><span class="line">        ......</span><br><span class="line">         <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">register</span><span class="params">(InstanceInfo info, <span class="type">boolean</span> isReplication)</span> &#123;</span><br><span class="line">                <span class="type">int</span> <span class="variable">leaseDuration</span> <span class="operator">=</span> <span class="number">90</span>;</span><br><span class="line">                <span class="keyword">if</span> (info.getLeaseInfo() != <span class="literal">null</span> &amp;&amp; info.getLeaseInfo().getDurationInSecs() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                    leaseDuration = info.getLeaseInfo().getDurationInSecs();</span><br><span class="line">                &#125;</span><br><span class="line">            <span class="comment">//完成注册。通过读写锁</span></span><br><span class="line">                <span class="built_in">super</span>.register(info, leaseDuration, isReplication);</span><br><span class="line">               <span class="comment">//往其他euraka服务器发送数据</span></span><br><span class="line">                <span class="built_in">this</span>.replicateToPeers(PeerAwareInstanceRegistryImpl.Action.Register, info.getAppName(), info.getId(), info, (InstanceStatus)<span class="literal">null</span>, isReplication);</span><br><span class="line">            &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="自我保护机制"><a href="#自我保护机制" class="headerlink" title="自我保护机制"></a>自我保护机制</h1><p>Eureka Server进入自我保护机制后，会出现以下情况：Eureka不再从注册列表中剔除因为长时间没收到心跳而过期的服务；Eureka Server依然可以接受新服务的注册和查询请求，但不会同步到其他节点；网络稳定时，当前实例新的注册信息会被同步到其他节点中。</p><p>自我保护机制是为了<em><strong>防止误杀服务</strong></em>。当个别客户端出现心跳失联，则认为是客户端的问题，剔除客户端；当Eureka捕获到大量的心跳失败，则认为可能是网络问题，进入自我保护；当客户端心跳恢复，Eureka会退出自我保护；</p><p>若在保护期内该服务提供者非正常下线，服务消费者会拿到无效的服务实例，就调用失败。</p><h1 id="对等复制架构"><a href="#对等复制架构" class="headerlink" title="对等复制架构"></a>对等复制架构</h1><p>Eureka本身依赖了Eureka Client，每个Server是作为其他Server 的Client。在单个Eureka Server启动，会有一个syncUP操作，通过Client请求其他Server节点中的一个节点获取注册应用实例信息，再复制到其他peer节点</p><p>EurekaServer采用Peer to peer的复制模式，重点解决数据复制的冲突问题：lastDirtyTimestamp标识和heartbeat。</p><p>针对数据不一致，一般通过比较版本号机制，最后在不同副本之间只需要判断请求复制数据的版本号与本地数据的版本号高地，eureka本身没有版本号属性，所以采用叫做lastDirtyTimestamp字段对比。peer节点之间的相互复制不能保证所有操作都能成功，所以eureka还通过应用实例与Server之间的heatbeat进行数据的最终修复，即发现应用实例数据与某个Server的数据出现不一致，则Server返回404，应用程序重新register。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;简述&quot;&gt;&lt;a href=&quot;#简述&quot; class=&quot;headerlink&quot; title=&quot;简述&quot;&gt;&lt;/a&gt;简述&lt;/h1&gt;&lt;p&gt;底层通过Jersey框架在AWS背景下实现，用过滤器做服务的拦截。核心就是把&lt;em&gt;&lt;strong&gt;过滤器注册进Tomcat&lt;/strong</summary>
      
    
    
    
    <category term="微服务" scheme="http://example.com/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
    
    <category term="Eureka" scheme="http://example.com/tags/Eureka/"/>
    
  </entry>
  
  <entry>
    <title>IOC和AOP</title>
    <link href="http://example.com/2022/08/22/IOC%E5%92%8CAOP/"/>
    <id>http://example.com/2022/08/22/IOC%E5%92%8CAOP/</id>
    <published>2022-08-22T11:55:28.000Z</published>
    <updated>2022-08-22T12:00:57.668Z</updated>
    
    <content type="html"><![CDATA[<h1 id="IOC"><a href="#IOC" class="headerlink" title="IOC"></a>IOC</h1><p>一种设计思想，控制反转，将设计好的对象交给容器控制。在调用某个类时，容器会实例化，即容器控制对象的创建。实际就是个BeanDefinitionMap，里面放的就是各种对象</p><p>IOC容器实例化过程中，一般不包含bean的依赖注入，bean的注册和依赖注入是两个过程，依赖注入一般发生在应用第一次索取bean的时候，但是也可以在xml中配置，在容器初始化的时候，这个bean就完成了初始化。</p><p>Bean是工厂模式创建；数据是通过反射注入，目的是降低耦合度</p><p><a href="https://xiaoerbutingbu.github.io/2022/06/14/Bean%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/">结合Bean的生命周期</a></p><h2 id="理解"><a href="#理解" class="headerlink" title="理解"></a>理解</h2><p>类比于：我自己找女朋友和我通过婚介公司找女朋友</p><p>控制反转，把我们写好的对象的控制权交给Spring框架，由框架来控制对象的生命周期（创建、销毁，这些对象之间的依赖关系），开发人员不用主动去new这些对象，IOC就是一个容器去创建这些对象，把所有的类都放到容器里面去登记，需要某个对象的时候告诉容器就行。</p><h1 id="AOP"><a href="#AOP" class="headerlink" title="AOP"></a>AOP</h1><p>  面向切面编程基于IOC。简单说就是将部分重复的代码抽取出来，需要执行的时候用动态代理价技术。不修改代码进行功能增强。<em><strong>解耦</strong></em></p><p>  降低了耦合度，提高了程序的可重用性，同时提高了开发效率</p><p>  底层使用动态代理</p><p>  实现业务和切入类的解耦</p><p>  与OOP相比，一个是横向一个纵向在</p><p>面向切面编程，使用了动态代理，两种实现方式：cglib和JDKProxy</p><h2 id="理解-1"><a href="#理解-1" class="headerlink" title="理解"></a>理解</h2><p>系统由不同的组件组成，不同组件负责不同的功能，会存在很多组件与业务无关（日志、事务、权限等等），而写组件经常融入具体的业务逻辑，若每个具体业务逻辑都添加这些代码，就代码冗余，所以需要将公共的代码逻辑抽象出来变成一个切面，然后注入到具体的业务中。</p><p>所以AOP基于该思路，采用动态代理的方式，将需要注入切面的对象进行代理，在进行调用时候只将公共逻辑添加进去，而不需要修改原有的逻辑代码，只需要在原来的业务逻辑基础上做一些增强功能即可。</p><h2 id="大致过程"><a href="#大致过程" class="headerlink" title="大致过程"></a>大致过程</h2><p>在bean进行初始化后，beanPostProcessor中有一个AnnotationAwareAspectjAutoProxyCreator的去生成bean对应的代理对象，然后通过getAdvicesAndAdvisorsForBean获取切面信息并返回所有通知的方法；再就是解析切面，通过beanName创建每个对应的Class，再通过遍历含有@Aspect注解类的每个方法，拿到含有@Before等标签的方法，方法即通知，为每个通知创建一个advisor对象并以List形式返回。再筛选作用域当前bean上的增强器；再通过ProxyFactory创建代理对象，返回的是AopProxy接口（cglib和JDK两个实现类）。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;IOC&quot;&gt;&lt;a href=&quot;#IOC&quot; class=&quot;headerlink&quot; title=&quot;IOC&quot;&gt;&lt;/a&gt;IOC&lt;/h1&gt;&lt;p&gt;一种设计思想，控制反转，将设计好的对象交给容器控制。在调用某个类时，容器会实例化，即容器控制对象的创建。实际就是个BeanDefin</summary>
      
    
    
    
    <category term="Spring" scheme="http://example.com/categories/Spring/"/>
    
    
    <category term="Spring" scheme="http://example.com/tags/Spring/"/>
    
  </entry>
  
  <entry>
    <title>IO多路复用模型</title>
    <link href="http://example.com/2022/08/19/IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/"/>
    <id>http://example.com/2022/08/19/IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/</id>
    <published>2022-08-18T21:48:05.000Z</published>
    <updated>2022-08-18T21:53:59.633Z</updated>
    
    <content type="html"><![CDATA[<h1 id="简述"><a href="#简述" class="headerlink" title="简述"></a>简述</h1><p>程通过告诉多路复用器（内核）所有的socket号，多路复用器再去获取每一个socket的状态，当程序获取到某个socket号有事件发生了，则去该socket号上进行处理对应的事件，read事件或者是recived事件。</p><p>一个线程监测多个IO操作</p><h1 id="Select模型"><a href="#Select模型" class="headerlink" title="Select模型"></a>Select模型</h1><p>属于linux下的标准函数。时间O(N)。</p><p>仅仅知道有几个I&#x2F;O事件发生，但不知道具体是哪几个socket连接有I&#x2F;O事件，还需要轮询去找。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">select</span><span class="params">(</span></span><br><span class="line"><span class="params">    <span class="comment">//需要监听和扫描最大fd个数</span></span></span><br><span class="line"><span class="params"><span class="type">int</span> maxfd,</span></span><br><span class="line"><span class="params">    <span class="comment">//本身是fdset集合，文件描述符。分别为 读事件列表、写事件列表、异常事件列表</span></span></span><br><span class="line"><span class="params">    fd_set *readset,</span></span><br><span class="line"><span class="params">    fd_set *writeset,</span></span><br><span class="line"><span class="params">    fd_set *exceptset,</span></span><br><span class="line"><span class="params">    <span class="comment">//监听时间，超时返回0，错误返回1，正常有数据可读的话就返回fd的个数</span></span></span><br><span class="line"><span class="params">    <span class="keyword">struct</span> timeval *timeout</span></span><br><span class="line"><span class="params">)</span>;</span><br></pre></td></tr></table></figure><p>   从用户空间拷贝fd_set到内核空间；再遍历所有fd文件，并将当前进程挂到每个fd的等待队列中，并将当前进程挂到每个fd的等待队列中，当某个fd文件收到消息后，会唤醒等待队列上睡眠的进程，那么当前进程就会被唤醒；若遍历完fd都没有I&#x2F;O事件，当前进程会睡眠直到某个fd文件有I&#x2F;O事件或睡眠超时</p><p>​    缺陷：&#x3D;&#x3D;对socket进行线性扫描（轮询）IO&#x3D;&#x3D;，效率低，程序不知道哪些socket收到数据，需要每次全部遍历，浪费CPU；限定大小，因为保存文件描述符的bitmaps32位是1024，64位2048；内核态与用户态频繁复制fd数据开销大；每次调用都要把fd从用户态拷贝到内核态；</p><p>交互流程：用户态监听socket，再调用select（然后用户态就开始线程阻塞），内核态执行准备数据，准备完毕后告诉用户态select可读，用户态就read请求，内核态数据拷贝到用户态，用户态read完成。就完成一个交互流程</p><h1 id="poll模型"><a href="#poll模型" class="headerlink" title="poll模型"></a>poll模型</h1><p>本质与select无区别；将用户给的数组拷贝进内核，查询每个fd对应设备的状态。时间O(N)</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">poll</span><span class="params">(</span></span><br><span class="line"><span class="params"><span class="keyword">struct</span> pollfd *fds, <span class="comment">//需要监听的文件描述符列表</span></span></span><br><span class="line"><span class="params">    <span class="type">unsigned</span> <span class="type">long</span> nfds,<span class="comment">//文件描述符个数</span></span></span><br><span class="line"><span class="params">    <span class="type">int</span> timeout  <span class="comment">//超时时间</span></span></span><br><span class="line"><span class="params">)</span>;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">pollfd</span>&#123;</span></span><br><span class="line">    <span class="type">int</span> fd;      <span class="comment">//需要监视的文件描述符</span></span><br><span class="line">    <span class="type">short</span> events;<span class="comment">//内核扫描的事件集合</span></span><br><span class="line">    <span class="type">short</span> revents;<span class="comment">//events扫描完派生出需要返回给用户态的数据</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>相比于select突破了1024的限制（因为采用了pollfd数据结构，是一个链表）；</p><p>标志准备就绪的，用户态只关心revents，内核态也不用重置原数据</p><p>若遍历fd都没有就绪设备就挂起当前线程，直到设备就绪或主动超时，被唤醒后再次遍历fd</p><p>​             没有最大连接次数（因为恢复revents）；大量fd数组复制进内核（有些无意义）；若报告的fd没处理，那下次poll会再次报告fd</p><p>​           有超时时间，5个FD拷贝到内核态并监听数据</p><p>​           有数据时内核会对revents字段置位，poll返回，遍历找置位读数据</p><h1 id="Epoll模型"><a href="#Epoll模型" class="headerlink" title="Epoll模型"></a>Epoll模型</h1><p>可水平触发（LT）和边缘触发（ET），默认是LT；<em><strong>不是轮询，是回调机制</strong></em>。O(1)</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//内核态创建epoll实例。底层是红黑树和就绪链表</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">epoll_create</span><span class="params">(<span class="type">int</span> size)</span>;</span><br><span class="line"><span class="comment">//对红黑树操作，添加所有socket节点</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">epoll_ctl</span><span class="params">(</span></span><br><span class="line"><span class="params"><span class="type">int</span> epfd,</span></span><br><span class="line"><span class="params">    <span class="type">int</span> op,</span></span><br><span class="line"><span class="params">    <span class="type">int</span> fd,</span></span><br><span class="line"><span class="params">    <span class="keyword">struct</span> epoll_event *event</span></span><br><span class="line"><span class="params">)</span>;</span><br><span class="line"><span class="comment">//线程阻塞，内核查找红黑树中ready的socket，放入就绪列表，就绪列表中内置内存到events</span></span><br><span class="line"><span class="comment">//算是事件通知，只把准备好的事件告诉用户态</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">epoll_wait</span><span class="params">(</span></span><br><span class="line"><span class="params"><span class="type">int</span> epfd,</span></span><br><span class="line"><span class="params">    <span class="keyword">struct</span> epoll_event *events,</span></span><br><span class="line"><span class="params">    <span class="type">int</span> maxevents,</span></span><br><span class="line"><span class="params">    <span class="type">int</span> timeout</span></span><br><span class="line"><span class="params">)</span>;</span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">union</span> <span class="title">epoll_data</span>&#123;</span></span><br><span class="line">    <span class="type">void</span> *ptr;</span><br><span class="line">    <span class="type">int</span> fd;</span><br><span class="line">    <span class="type">uint32_t</span> u32;</span><br><span class="line">    <span class="type">uint64_t</span> u64;</span><br><span class="line">&#125;<span class="type">epoll_data_t</span>;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">epoll_event</span>&#123;</span></span><br><span class="line">    <span class="type">uint32_t</span> events,</span><br><span class="line">    <span class="type">epoll_data_t</span> data;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>没有最大并发连接的限制；效率提升；内存拷贝</p><p>​             连接数较多且很多的不活跃连接时，epoll效率更好；反之，epoll因需要回调，所以性能此时会低</p><p>每个文件描述符上都有一个callback函数，当socket有事件时会回调这个函数将该fd的引用放到列表中，且会指出哪些文件描述符就绪。所以，可以直接处理</p><p>LT（阻塞和非阻塞皆可）：当文件描述符上的事件就绪后，若事务没有处理完或没有处理，那epoll会在下次提醒应用程序。就是内核会持续通知文件描述符已经就绪，我就可以对就绪的FD执行I&#x2F;O操作。</p><p>ET（仅阻塞）：当文件描述符上的事件就绪后，若事务没有处理完或没有处理，下一次epoll就不会提醒应用程序</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;简述&quot;&gt;&lt;a href=&quot;#简述&quot; class=&quot;headerlink&quot; title=&quot;简述&quot;&gt;&lt;/a&gt;简述&lt;/h1&gt;&lt;p&gt;程通过告诉多路复用器（内核）所有的socket号，多路复用器再去获取每一个socket的状态，当程序获取到某个socket号有事件发生了，则</summary>
      
    
    
    
    <category term="基础" scheme="http://example.com/categories/%E5%9F%BA%E7%A1%80/"/>
    
    
    <category term="IO模型" scheme="http://example.com/tags/IO%E6%A8%A1%E5%9E%8B/"/>
    
  </entry>
  
  <entry>
    <title>Mybatis核心类</title>
    <link href="http://example.com/2022/08/17/Mybatis%E6%A0%B8%E5%BF%83%E7%B1%BB/"/>
    <id>http://example.com/2022/08/17/Mybatis%E6%A0%B8%E5%BF%83%E7%B1%BB/</id>
    <published>2022-08-16T17:38:46.000Z</published>
    <updated>2022-08-16T17:44:30.951Z</updated>
    
    <content type="html"><![CDATA[<h1 id="SqlSessionFactoryBuilder"><a href="#SqlSessionFactoryBuilder" class="headerlink" title="SqlSessionFactoryBuilder"></a>SqlSessionFactoryBuilder</h1><p>是利用XML或Java编码编码获得资源来构建SqlSessionFactory（可以构建多个），一旦构建完，作用就没了，就可以回收。它的生命周期只存在与方法的局部，<em><strong>作用就是生产SqlSessionFactory</strong></em></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SqlSessionFactoryBuilder</span> &#123;</span><br><span class="line">    <span class="comment">//各种构造方法</span></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">SqlSessionFactoryBuilder</span><span class="params">()</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> SqlSessionFactory <span class="title function_">build</span><span class="params">(Reader reader)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">this</span>.build((Reader)reader, (String)<span class="literal">null</span>, (Properties)<span class="literal">null</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> SqlSessionFactory <span class="title function_">build</span><span class="params">(Reader reader, String environment)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">this</span>.build((Reader)reader, environment, (Properties)<span class="literal">null</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> SqlSessionFactory <span class="title function_">build</span><span class="params">(Reader reader, Properties properties)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">this</span>.build((Reader)reader, (String)<span class="literal">null</span>, properties);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> SqlSessionFactory <span class="title function_">build</span><span class="params">(Reader reader, String environment, Properties properties)</span> &#123;</span><br><span class="line">        SqlSessionFactory var5;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//获得XMLConfigBuilder，new出一个成员变量configuration</span></span><br><span class="line">            <span class="type">XMLConfigBuilder</span> <span class="variable">parser</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">XMLConfigBuilder</span>(reader, environment, properties);</span><br><span class="line">            var5 = <span class="built_in">this</span>.build(parser.parse());</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception var14) &#123;</span><br><span class="line">            <span class="keyword">throw</span> ExceptionFactory.wrapException(<span class="string">&quot;Error building SqlSession.&quot;</span>, var14);</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            ErrorContext.instance().reset();</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                reader.close();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (IOException var13) &#123;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> var5;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> SqlSessionFactory <span class="title function_">build</span><span class="params">(InputStream inputStream)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">this</span>.build((InputStream)inputStream, (String)<span class="literal">null</span>, (Properties)<span class="literal">null</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> SqlSessionFactory <span class="title function_">build</span><span class="params">(InputStream inputStream, String environment)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">this</span>.build((InputStream)inputStream, environment, (Properties)<span class="literal">null</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> SqlSessionFactory <span class="title function_">build</span><span class="params">(InputStream inputStream, Properties properties)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">this</span>.build((InputStream)inputStream, (String)<span class="literal">null</span>, properties);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> SqlSessionFactory <span class="title function_">build</span><span class="params">(InputStream inputStream, String environment, Properties properties)</span> &#123;</span><br><span class="line">        SqlSessionFactory var5;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="type">XMLConfigBuilder</span> <span class="variable">parser</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">XMLConfigBuilder</span>(inputStream, environment, properties);</span><br><span class="line">            var5 = <span class="built_in">this</span>.build(parser.parse());</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception var14) &#123;</span><br><span class="line">            <span class="keyword">throw</span> ExceptionFactory.wrapException(<span class="string">&quot;Error building SqlSession.&quot;</span>, var14);</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            ErrorContext.instance().reset();</span><br><span class="line"></span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                inputStream.close();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (IOException var13) &#123;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> var5;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> SqlSessionFactory <span class="title function_">build</span><span class="params">(Configuration config)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">DefaultSqlSessionFactory</span>(config);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="SqlSessionFactory"><a href="#SqlSessionFactory" class="headerlink" title="SqlSessionFactory"></a>SqlSessionFactory</h1><p>每个基于MyBatis的应用都是一个SqlSessionFactory的实例为中心的，该实例通过SqlSessionFactoryBuilder获得。而Builder可以从XML配置文件或通过java的方式构建SqlSessionFactory实例。</p><p><em><strong>作用就是去创建SqlSession</strong></em>。每次应用需要访问数据库，就要通过SqlSessionFactory创建SqlSession。若多次创建同一个数据库的SqlSessionFactory，则每次创建的都会打开更多数据库连接资源，所以连接资源会被消耗。所以<em><strong>SqlSessionFactory是唯一的</strong></em>，于是采用单例模式，若采用多例就对数据库连接消耗大且不利于管理</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">SqlSessionFactory</span> &#123;</span><br><span class="line">    SqlSession <span class="title function_">openSession</span><span class="params">()</span>;</span><br><span class="line">    SqlSession <span class="title function_">openSession</span><span class="params">(<span class="type">boolean</span> var1)</span>;</span><br><span class="line">    SqlSession <span class="title function_">openSession</span><span class="params">(Connection var1)</span>;</span><br><span class="line">    SqlSession <span class="title function_">openSession</span><span class="params">(TransactionIsolationLevel var1)</span>;</span><br><span class="line">    SqlSession <span class="title function_">openSession</span><span class="params">(ExecutorType var1)</span>;</span><br><span class="line">    SqlSession <span class="title function_">openSession</span><span class="params">(ExecutorType var1, <span class="type">boolean</span> var2)</span>;</span><br><span class="line">    SqlSession <span class="title function_">openSession</span><span class="params">(ExecutorType var1, TransactionIsolationLevel var2)</span>;</span><br><span class="line">    SqlSession <span class="title function_">openSession</span><span class="params">(ExecutorType var1, Connection var2)</span>;</span><br><span class="line">    Configuration <span class="title function_">getConfiguration</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>一个工厂，创建SqlSession对象，SqlSession是MyBatis面向数据库的高级接口，提供了执行查询sql、更新sql等</p><h2 id="构建"><a href="#构建" class="headerlink" title="构建"></a>构建</h2><p>首先需要提供配置文件和相关的参数。采用<em><strong>构造模式</strong></em>去创建SqlSessionFactory，通过SqlSessionFactoryBuilder构建</p><p>分两步：</p><p>​解析XML文件，读出配置参数，将读取的数据存入Configuration（MyBatis基本所有的配置都是在这）</p><p>​使用Configurattion对象去创建SqlSessionFactory。因SqlSessionFactory本身是一个接口，一般情况使用其实现类之中的DefaultSqlSessionFactory。</p><h2 id="Configuration"><a href="#Configuration" class="headerlink" title="Configuration"></a>Configuration</h2><p>作用：读入配置文件，包括基础配置XML文件和映射器XML文件；初始化基础配置（别名啊、类的对象啊）；提供单例，为后续创建SessionFactory服务并提供配置的参数；执行一些重要的对象的方法，初始化配置信息；</p><p>configuration做的初始化信息：全局参数、设置、别名、插件、类型处理器等等</p><h1 id="SqlSession"><a href="#SqlSession" class="headerlink" title="SqlSession"></a>SqlSession</h1><p>MyBatis的顶层API接口，作为会话访问，完成CRUD，有两个实现类，通过内部存放的执行器来对数据进行CRUD操作，<em><strong>非线程安全</strong></em>，所以每次都要close关闭。</p><p>一个会话，相当于JDBC的一个Connection对象，长期的存在会让数据库连接池的活动资源减少</p><h2 id="四大对象"><a href="#四大对象" class="headerlink" title="四大对象"></a>四大对象</h2><p>映射器就是一个动态代理对象，进入到MapperMethod的executte方法。</p><h3 id="执行器"><a href="#执行器" class="headerlink" title="执行器"></a>执行器</h3><p>真正执行Java和数据库交互的东西。</p><p>有三种：</p><p>​SIMPLE：简易执行器，默认的</p><p>​REUSE：执行器重用预处理语句</p><p>​BATCH：执行器重用语句和批量更新，针对批量专用的执行器</p><p>三种都提供了查询和更新方法，以及相关的事务方法</p><h3 id="数据库会话器"><a href="#数据库会话器" class="headerlink" title="数据库会话器"></a>数据库会话器</h3><p>专门处理数据库会话的。</p><p>定义了一个对象的适配器delegate，根据配置来适配对应的StatementHandler对象。作用就是给实现类对象的使用提供一个同一、简易的使用适配器。可以使用现有的类和方法对外提供服务、可以根据实际的需求对外屏蔽一些方法甚至加入新服务。</p><h3 id="参数处理器"><a href="#参数处理器" class="headerlink" title="参数处理器"></a>参数处理器</h3><p>参数处理器对预编译语句进行参数设置</p><h3 id="结果处理器"><a href="#结果处理器" class="headerlink" title="结果处理器"></a>结果处理器</h3><p>组装结果集的返回。</p><p>MyBatis提供了DefaultResultSetHandler类，默认状况都是这个类进行处理</p><h2 id="大致过程"><a href="#大致过程" class="headerlink" title="大致过程"></a>大致过程</h2><p>SqlSession是通过Executor创建StatementHandler运行，statement需要经过：</p><ul><li>prepared预编译SQL</li><li>parameterize设置参数：调用paremeterHandler方法设置，参数类型根据类型处理器typeHandler处理</li><li>query&#x2F;update执行SQL：通过resultHandler进行处理结果的封装，若是update就返回整数，反之通过typeHandler处理结果类型，再用ObjectFactory提供的规则组装对象，返回调用者</li></ul><h1 id="Mapper"><a href="#Mapper" class="headerlink" title="Mapper"></a>Mapper</h1><p>一个接口，没有任何实现类，作用就是发送SQL，在一个SqlSession事务方法之内，是一个方法级别的东西。如果JDBC的一条SQL语句执行。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;SqlSessionFactoryBuilder&quot;&gt;&lt;a href=&quot;#SqlSessionFactoryBuilder&quot; class=&quot;headerlink&quot; title=&quot;SqlSessionFactoryBuilder&quot;&gt;&lt;/a&gt;SqlSessionFact</summary>
      
    
    
    
    <category term="Mybatis" scheme="http://example.com/categories/Mybatis/"/>
    
    
    <category term="Mybatis" scheme="http://example.com/tags/Mybatis/"/>
    
  </entry>
  
  <entry>
    <title>数据链路层</title>
    <link href="http://example.com/2022/08/13/MAC/"/>
    <id>http://example.com/2022/08/13/MAC/</id>
    <published>2022-08-12T20:15:17.000Z</published>
    <updated>2022-08-12T20:24:46.098Z</updated>
    
    <content type="html"><![CDATA[<h1 id="数据链路层"><a href="#数据链路层" class="headerlink" title="数据链路层"></a>数据链路层</h1><p>MAC（数据链路层）是实现 直连 两个设备之间通信</p><h1 id="简述"><a href="#简述" class="headerlink" title="简述"></a>简述</h1><p>该层是负责通过一条链路从一个节点向另一个物理链路直接相连的相邻节点传送数据报</p><p>该层是在物理层提供服务的基础上向网络层提供服务，最基本的就是将原子网络层的数据可靠的传输到相邻节点的目标机网络层。作用是<em><strong>加强物理层传输原始比特流的功能</strong></em>，将物理层提供的可能出错的物理连续改造为***逻辑上无差错的数据</p><p>使用的信道有两种：点对点信道和广播信道</p><h1 id="三大特定"><a href="#三大特定" class="headerlink" title="三大特定"></a>三大特定</h1><h2 id="封装成帧"><a href="#封装成帧" class="headerlink" title="封装成帧"></a>封装成帧</h2><p>帧：链路层的协议数据单元，封装网络层数据报。<em><strong>只有数据链路层才能识别帧，物理层只是传输比特流</strong></em></p><p>因为物理层只是负责传输，无法控制和判断是否出错，且在传输过程中容易受到环境干扰，进行产生错误。于是数据链路层需要负责<em><strong>差错检测</strong></em>的工作</p><h3 id="帧的结构"><a href="#帧的结构" class="headerlink" title="帧的结构"></a>帧的结构</h3><p>网络层将IP数据报传送到数据链路层作为帧的数据部分，数据链表路层分别在前后增加了一个标记（SOH和EOT），作为数据开始和结束。帧在物理层就是一串01比特流。<em><strong>帧首部和尾部是特定的控制字符</strong></em></p><p>​||帧首部||帧数据部分||帧尾部||</p><h2 id="透明传输"><a href="#透明传输" class="headerlink" title="透明传输"></a>透明传输</h2><p>无论什么样的比特组合的数据能通过数据链路层。数据看不见链路层有什么阻碍数据传输的东西，所以对这些数据来说就是透明的。</p><p>解决：发送端的数据链路层在数据中出现控制字符（EOT或SOH）的前面插入一个转义字符（ESC）。字节填充或字符填充</p><p>方法有比特填充法和字符填充</p><p>&#x3D;&#x3D;帧采用零比特填充&#x3D;&#x3D;：发送端发现有连续的5个1，就填入1个0；接收端发现有5个连续的1就删除其后的0。</p><h2 id="差错检测"><a href="#差错检测" class="headerlink" title="差错检测"></a>差错检测</h2><p>在传输过程中可能出现比特差错：1和0可能变化。为了保证数据传输的可靠性，在计网传输数据时，必须采用各种差错检测措施。</p><p>奇偶校验码和循环冗余检验码CRC。</p><h1 id="ARP协议"><a href="#ARP协议" class="headerlink" title="ARP协议"></a>ARP协议</h1><p><img src="/2022/08/13/MAC/data.png"></p><p>根据IP地址寻找MAC地址</p><p>源MAC地址就是发送数据的计算机的MAC地址，很轻易获取</p><h2 id="公理"><a href="#公理" class="headerlink" title="公理"></a>公理</h2><p>每一个计算机或路由器都有一个<em><strong>ARP高速缓存表</strong></em>，也就是IP地址与MAC地址的映射表</p><p>ARP高速缓存表中只会存储<em><strong>当前局域网</strong></em>内的设备信息，包括不限于连接此局域网接口所对应的<em><strong>IP与MAC映射信息</strong></em></p><h2 id="执行原理"><a href="#执行原理" class="headerlink" title="执行原理"></a>执行原理</h2><p>首先计算机判断目的IP地址是否是同网段的IP</p><h3 id="源主机和目标主机在同一局域网"><a href="#源主机和目标主机在同一局域网" class="headerlink" title="源主机和目标主机在同一局域网"></a>源主机和目标主机在同一局域网</h3><p>计算机在ARP地址表中查询目的IP地址</p><p>若ARP地址表能查到，就会获取IP地址对应的MAC地址，将信息发送到这个MAC地址对应的计算机中。</p><p>若ARP地址表查不到，就以<em><strong>单播</strong></em>的方式，将自己的IP地址和MAC地址根据请求中的源IP地址响应给计算机；计算机将接收到到IP地址和MAC地址添加到自己的ARP地址表中，再根据MAC地址将数据发送给对方</p><h4 id="源主机和目标主机在不同局域网"><a href="#源主机和目标主机在不同局域网" class="headerlink" title="源主机和目标主机在不同局域网"></a>源主机和目标主机在不同局域网</h4><p>计算机通过路由器与局域网的连接口，先将数据发送给路由器（路由器的每个接口都有对应的IP地址和MAC地址），路由器通过算法选择最优路线将信息发给<em><strong>目标主机所在局域网的路由器上</strong></em></p><p>目标主机的路由器收到信息后，先检查自己的ARP地址表：若有目标IP地址，就直接发；若没有，在局域网内&#x3D;&#x3D;广播&#x3D;&#x3D;，目标主机收到广播后会返回自己的IP和MAC地址，路由器将收到IP地址和MAC地址并存储到自己的ARP地址表中，然后发主机过去</p><h2 id="流程图"><a href="#流程图" class="headerlink" title="流程图"></a>流程图</h2><p><img src="/2022/08/13/MAC/liucheng.png"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;数据链路层&quot;&gt;&lt;a href=&quot;#数据链路层&quot; class=&quot;headerlink&quot; title=&quot;数据链路层&quot;&gt;&lt;/a&gt;数据链路层&lt;/h1&gt;&lt;p&gt;MAC（数据链路层）是实现 直连 两个设备之间通信&lt;/p&gt;
&lt;h1 id=&quot;简述&quot;&gt;&lt;a href=&quot;#简述&quot; cl</summary>
      
    
    
    
    <category term="计算机网络" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    
    <category term="计算机网络" scheme="http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>Redis数据结构</title>
    <link href="http://example.com/2022/08/11/Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    <id>http://example.com/2022/08/11/Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</id>
    <published>2022-08-10T17:30:38.000Z</published>
    <updated>2022-08-10T17:36:33.157Z</updated>
    
    <content type="html"><![CDATA[<h1 id="String"><a href="#String" class="headerlink" title="String"></a>String</h1><p>最基本的，动态可修改字符串，二进制安全，存数字时底层是int编码；长字符串（长度&gt;39字节）raw编码；短字符串（长度&lt;39字节）embstr编码。长度不能超过512MB。整体类似于ArrayList</p><p>​存储double类型的浮点数是先转换为字符串再存储。raw和embstr编码效果相同，不同于内存分配释放，raw一次，embstr两次；embstr内存快连续，能更好的利用缓存带来的优势；</p><p>利用key的生命周期做投票系统；String特点数据刷新；利用数值操作特征为分布式数据库自增。访问次数、点赞、转发量；计数器、限流。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//底层</span></span><br><span class="line">struct sdshdr&#123;</span><br><span class="line">    <span class="comment">//记录SDS所保存的字符串长度</span></span><br><span class="line"><span class="type">int</span> len;</span><br><span class="line">    <span class="comment">//记录buf数组未使用的空间数量</span></span><br><span class="line"><span class="type">int</span> free;</span><br><span class="line">    <span class="comment">//字符串数组，保存字符串</span></span><br><span class="line"><span class="type">char</span> buf[];</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//综上：常数获取字符串长度；避免缓冲区移除；减少重分配次数：内存不足时，会触发自动扩容；SDS API会以处理二进制的方式处理存放的buf数组里的数据，程序不会对其中做任何限制、过滤、假设，二进制安全；</span></span><br></pre></td></tr></table></figure><p>del key,get key,set key value</p><h1 id="List"><a href="#List" class="headerlink" title="List"></a>List</h1><p>简单的字符串列表，<em><strong>底层是linkedlist和ziplist</strong></em>（元素数量&lt;512，所有对象元素长度小于64字节就使用ziplist反之就linkedlist）。</p><p>​ziplist：将所有元素紧挨着一起存储，分配的是一块连续的内存</p><p>​linkedlist:会有前驱后驱指针</p><p>可用于消息队列；顺序特性实现朋友圈点赞；顺序特性进行分布式日志顺序性展示；发布和订阅；慢查询</p><p>  Lpush,lpop,rpop,rush,</p><h1 id="Hash"><a href="#Hash" class="headerlink" title="Hash"></a>Hash</h1><p>是一个键值对集合，是一个String类型的key和value的映射表。相当于hashmap。存放对象类型的数据，可避免键名冲突。 用户的购物车；hash作为商品秒杀技术对象完成商品秒杀系统</p><p>底层：ziplist（元素数量&lt;512个，所有值&lt;64字节）和hashtable</p><p>redis为了提高性能，不能阻塞服务，采用了渐进式策略</p><p>hset,hgetall,hlen,hget</p><p>用来缓存作为用户信息</p><h1 id="Set"><a href="#Set" class="headerlink" title="Set"></a>Set</h1><p>String类型的无序集合，底层哈希表和intset（所有元素是整数，元素数量小于512）</p><p>​intset：有序不重复的连续空间；</p><p>sadd key element[ ]</p><p>比如标签；黑白名单；获取所有业务的权限、用户标签</p><h1 id="ZSet"><a href="#ZSet" class="headerlink" title="ZSet"></a>ZSet</h1><p>组成：ziplist（元素数量小于128，所有元素长度&lt;64）和跳跃表+哈希结合，value保证唯一性，又可为每个value代表权重的值。</p><p>跳表：每一层都是一个有序链表，默认升序。跳表中有表头节点和表尾节点。zskiplistNode中包含层、后退指针、分值、成员对象。底层拥有所有元素，插入元素的时候会随机生成一个“层次数字”，然后元素插入达到这个层次的所有底层，直到原始链表层</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">typedef struct zset &#123;</span><br><span class="line">    dict *dict;</span><br><span class="line">    zskiplist *zsl;<span class="comment">//跳表，目的就是为了高效支持范围查找</span></span><br><span class="line">&#125; zset;</span><br><span class="line"><span class="comment">//跳表节点</span></span><br><span class="line">typedef struct zskiplistNode &#123;</span><br><span class="line">    <span class="comment">//保存数据</span></span><br><span class="line">    sds ele;</span><br><span class="line">    <span class="comment">//权重</span></span><br><span class="line">    <span class="type">double</span> score;</span><br><span class="line">    <span class="comment">//后向指针</span></span><br><span class="line">    struct zskiplistNode *backward;</span><br><span class="line">    level数组</span><br><span class="line">    struct zskiplistLevel &#123;</span><br><span class="line">        <span class="comment">//前向指针</span></span><br><span class="line">        struct zskiplistNode *forward;</span><br><span class="line">        <span class="comment">//跨度，记录跨越了level0上的几个结点</span></span><br><span class="line">        unsigned <span class="type">long</span> span;</span><br><span class="line">    &#125; level[];</span><br><span class="line">&#125; zskiplistNode;</span><br><span class="line"><span class="comment">//跳表</span></span><br><span class="line">typedef struct zskiplist &#123;</span><br><span class="line">   <span class="comment">//跳表的头结点和尾结点 </span></span><br><span class="line">    struct zskiplistNode *header, *tail;</span><br><span class="line">   <span class="comment">//最大长度 </span></span><br><span class="line">    unsigned <span class="type">long</span> length;</span><br><span class="line">   <span class="comment">//最大层数 </span></span><br><span class="line">    <span class="type">int</span> level;</span><br><span class="line">&#125; zskiplist;</span><br></pre></td></tr></table></figure><p>查找</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//跳表会从头节点的最高层开始查找下一个节点，因为节点中有元素和权值，所以两者都要比较</span></span><br><span class="line"><span class="comment">//若当前定位的元素权值更小，就访问该层下一个节点</span></span><br><span class="line"><span class="comment">//若当前定位的元素权值与需要查询的权值相同，就比较元素值，若定位的元素值数据更小，还是访问该层下一个节点</span></span><br><span class="line"><span class="comment">//以上两个条件都不满足就会访问level数组的下一层指针，沿着下一层指针找</span></span><br><span class="line">x = zsl-&gt;header;</span><br><span class="line">    <span class="keyword">for</span> (i = zsl-&gt;level-<span class="number">1</span>; i &gt;= <span class="number">0</span>; i--) &#123;</span><br><span class="line">       ...</span><br><span class="line">        <span class="keyword">while</span> (x-&gt;level[i].forward &amp;&amp;</span><br><span class="line">                (x-&gt;level[i].forward-&gt;score &lt; score ||</span><br><span class="line">                    (x-&gt;level[i].forward-&gt;score == score &amp;&amp;</span><br><span class="line">                    sdscmp(x-&gt;level[i].forward-&gt;ele,ele) &lt; <span class="number">0</span>)))</span><br><span class="line">        &#123;</span><br><span class="line">           ...</span><br><span class="line">            x = x-&gt;level[i].forward;</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure><p>跳表在创建节点的时候，采用了随机生成节点层数的方法。&lt;&#x3D;25%</p><p>排行榜系统；带权重任务队列；根据权重进行排序</p><p>zadd  key score member[]</p><p>搜索路径如图：要检索19</p><p><img src="/2022/08/11/Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/19.png"></p><h1 id="高级"><a href="#高级" class="headerlink" title="高级"></a>高级</h1><p>Bitmaps:String类型上的一组面向bit操作的集合，不是真的数据结构，优点就是存储信息可节省大量空间。一般用于实时分析，存储对象ID关联的节省空间且高性能的布尔信息。底层是String</p><p>HyperLogLogs：用于计算唯一事物的概率数据结构。可用于计算用户每天在搜索框中执行唯一的搜索。底层是String</p><p>  GEO：存储用户给定的地理位置信息，并对这些信息操作。底层是zset</p><p>  Streams：内存版的kafka</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;String&quot;&gt;&lt;a href=&quot;#String&quot; class=&quot;headerlink&quot; title=&quot;String&quot;&gt;&lt;/a&gt;String&lt;/h1&gt;&lt;p&gt;最基本的，动态可修改字符串，二进制安全，存数字时底层是int编码；长字符串（长度&amp;gt;39字节）raw编码</summary>
      
    
    
    
    <category term="redis" scheme="http://example.com/categories/redis/"/>
    
    
    <category term="redis" scheme="http://example.com/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>基础题1</title>
    <link href="http://example.com/2022/08/09/%E5%B8%B8%E8%A7%81%E5%9F%BA%E7%A1%80%E9%A2%981/"/>
    <id>http://example.com/2022/08/09/%E5%B8%B8%E8%A7%81%E5%9F%BA%E7%A1%80%E9%A2%981/</id>
    <published>2022-08-08T16:11:35.000Z</published>
    <updated>2022-08-08T16:28:37.133Z</updated>
    
    <content type="html"><![CDATA[<h1 id="StringBuilder和StringBuffer"><a href="#StringBuilder和StringBuffer" class="headerlink" title="StringBuilder和StringBuffer"></a>StringBuilder和StringBuffer</h1><p>Java9之后就是通过byte[] value 实现</p><p><img src="/2022/08/09/%E5%B8%B8%E8%A7%81%E5%9F%BA%E7%A1%80%E9%A2%981/String.png"></p><h1 id="Final"><a href="#Final" class="headerlink" title="Final"></a>Final</h1><p>主要用在 变量、方法、类</p><p>修饰类对象的时候，属性值还是可以变化。</p><p>使用原因：把方法锁定，防止任何类修改它的含义；提升效率性能；多线程下保持了线程安全。</p><p>修饰基本类型值不变，<em><strong>修饰引用类型只是引用不可变，但是引用所指向的地址的内容可以改变</strong></em></p><p><strong>只被final修饰但是没给初始值的情况下的基本数据类型是可以通过反射改变值</strong></p><p>final修饰的属性的初始化可以在编译器、运行期，初始化后不能被改变</p><h2 id="了解"><a href="#了解" class="headerlink" title="了解"></a>了解</h2><p>当变量被static final修饰时，该变量的值是不能被改变且必须给初始值；</p><p>只被final修饰的变量在定义时没给初始值是能通过反射改变代码运行期间所赋予的值，而在定义时就给了初始值的通过反射也不能改变值</p><h1 id="为什么重写equals要重写hashcode"><a href="#为什么重写equals要重写hashcode" class="headerlink" title="为什么重写equals要重写hashcode"></a>为什么重写equals要重写hashcode</h1><p><img src="/2022/08/09/%E5%B8%B8%E8%A7%81%E5%9F%BA%E7%A1%80%E9%A2%981/hashcode.png"></p><p>首先hashCode是一个本地方法，不同虚拟机有不同实现，主要是为了给HashMap这样的哈希表的使用。</p><p>设计该方法的重要因素：对同一个对象调用该方法应该产生相同的值，所以需要快、不需要唯一性。</p><p>equals相等，hashcode一定相等：</p><p>equals不等，hashcode不一定不等：这是为了尽量减少哈希冲突，因为hashcode是int类型，有范围，难免冲突，此时hashmap通过拉链法解决冲突</p><p>hashcode不等，equals一定不等</p><p>hashcode相等，equals不一定相等</p><p>综上：</p><p>若重写equals，就一定要重写hashCode</p><p>提高效率：先进行hashcode比较，若不同就不用再比较，就提高了效率</p><h1 id="抽象类（JDK8）"><a href="#抽象类（JDK8）" class="headerlink" title="抽象类（JDK8）"></a>抽象类（JDK8）</h1><p>不一定要有抽象方法</p><p>不能用final修饰，因为final修饰了就不能被修改和继承了</p><h2 id="与接口的区别"><a href="#与接口的区别" class="headerlink" title="与接口的区别"></a>与接口的区别</h2><ul><li>抽象类可以提供成员方法的实现细节，而接口只能包含抽象方法、普通方法。</li><li>抽象类的成员变量可以是各种类型，接口中的成员变量只能是public static final</li><li>抽象类可有静态代码和静态静态方法，接口不能含有静态代码块和静态方法</li><li>抽象类可有构造器，接口不能有有构造器</li><li>一个子类只存在一个父类，一个子类可以存在多个接口</li></ul><h2 id="与普通类"><a href="#与普通类" class="headerlink" title="与普通类"></a>与普通类</h2><p>普通类：不能含有抽象方法，可以直接实例化</p><p>抽象类：可以有抽象方法，不能直接实例化</p><h1 id="x3D-x3D-和equals"><a href="#x3D-x3D-和equals" class="headerlink" title="&#x3D;&#x3D;和equals"></a>&#x3D;&#x3D;和equals</h1><table><thead><tr><th align="center">&#x3D;&#x3D;</th><th align="center">Equals</th></tr></thead><tbody><tr><td align="center">运算符</td><td align="center">方法</td></tr><tr><td align="center">若比较基本类型，则比较数值（即使数据类型不同，比如 int  i&#x3D;1,double k &#x3D;1.0）；若是引用数据类型，则比较内存地址值</td><td align="center">比较方法的两个对象内容是否相等  不能比较基本数据类型的变量；  若没有重写（也是默认情况），则比较的是引用数据类型的变量所指向的对象的地址</td></tr><tr><td align="center">比较浮点型数据时导致数据精度丢失</td><td align="center"></td></tr></tbody></table><h1 id="解决Hash冲突"><a href="#解决Hash冲突" class="headerlink" title="解决Hash冲突"></a>解决Hash冲突</h1><p>开放地址法：一旦发生了冲突，就寻找下一个空的散列地址。 H<del>i</del>&#x3D; (H(key) + d<del>i</del>)%m;  m为哈希表长，d<del>i</del>为增量序列</p><p>再哈希算法：一直调用哈希函数，计算地址，直到没有冲突。不易发生聚集，但增加了计算时间</p><p>链地址（HashMap所用）：每个哈希表节点都有一个next指针，多个哈希表节点可以用next指针构成单向链表，被分配到同一个索引上的多个节点可以用这个单向链表连接。</p><p>建立公共溢出区：将哈希表分为基本表和溢出表两个部分，凡是和基本表发生冲突的元素都填入溢出表</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;StringBuilder和StringBuffer&quot;&gt;&lt;a href=&quot;#StringBuilder和StringBuffer&quot; class=&quot;headerlink&quot; title=&quot;StringBuilder和StringBuffer&quot;&gt;&lt;/a&gt;StringBu</summary>
      
    
    
    
    <category term="基础" scheme="http://example.com/categories/%E5%9F%BA%E7%A1%80/"/>
    
    
    <category term="题" scheme="http://example.com/tags/%E9%A2%98/"/>
    
  </entry>
  
</feed>
